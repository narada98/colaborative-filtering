{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Libraries"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"1HtSQmz6NwiT"},"outputs":[],"source":["from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n","from recommenders.models.cornac.cornac_utils import predict_ranking\n","import itertools as it\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import trange\n","\n","\n","import pandas as pd\n","import os\n","from datetime import datetime\n","import numpy as np\n","\n","from cornac.models.recommender import Recommender\n","from cornac.utils.common import scale\n","from cornac.exception import ScoreException\n","from cornac.eval_methods import StratifiedSplit, RatioSplit\n","from cornac.data import Dataset\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import KFold\n","import statistics\n","import cornac\n","from sklearn.model_selection import StratifiedKFold\n","\n","from cornac.models.recommender import ANNMixin, MEASURE_DOT"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{},"source":["## Architecture"]},{"cell_type":"code","execution_count":103,"metadata":{"executionInfo":{"elapsed":5211,"status":"ok","timestamp":1705994223858,"user":{"displayName":"Narada Wijerathne","userId":"01570151137951130679"},"user_tz":-330},"id":"6BNCFwYWV4j2"},"outputs":[],"source":["EPS = 1e-10\n","\n","ACT = {\n","    \"sigmoid\": nn.Sigmoid(),\n","    \"tanh\": nn.Tanh(),\n","    \"elu\": nn.ELU(),\n","    \"relu\": nn.ReLU(),\n","    \"relu6\": nn.ReLU6(),\n","}\n","\n","\n","class BiVAE(nn.Module):\n","    def __init__(\n","        self,\n","        k,\n","        user_encoder_structure,\n","        item_encoder_structure,\n","        act_fn,\n","        likelihood,\n","        cap_priors,\n","        feature_dim,\n","        user_batch_size,\n","        item_batch_size,\n","    ):\n","        super(BiVAE, self).__init__()\n","\n","\n","        #initializes mu_theta, mu_beta, theta and beta tensors\n","        self.mu_theta = torch.zeros((item_encoder_structure[0], k))  # n_users*k\n","        self.mu_beta = torch.zeros((user_encoder_structure[0], k))  # n_items*k\n","\n","        self.theta = torch.randn(item_encoder_structure[0], k) * 0.01\n","        self.beta = torch.randn(user_encoder_structure[0], k) * 0.01\n","        torch.nn.init.kaiming_uniform_(self.theta, a=np.sqrt(5))\n","\n","        self.likelihood = likelihood\n","        self.act_fn = ACT.get(act_fn, None)\n","        if self.act_fn is None:\n","            raise ValueError(\"Supported act_fn: {}\".format(ACT.keys()))\n","\n","        self.cap_priors = cap_priors\n","        if self.cap_priors.get(\"user\", False):\n","            self.user_prior_encoder = nn.Linear(feature_dim.get(\"user\"), k)\n","        if self.cap_priors.get(\"item\", False):\n","            self.item_prior_encoder = nn.Linear(feature_dim.get(\"item\"), k)\n","\n","        # User Encoder\n","        self.user_encoder = nn.Sequential()\n","        for i in range(len(user_encoder_structure) - 1):\n","            self.user_encoder.add_module(\n","                \"fc{}\".format(i),\n","                nn.Linear(user_encoder_structure[i], user_encoder_structure[i + 1]),\n","            )\n","            self.user_encoder.add_module(\"act{}\".format(i), self.act_fn)\n","        self.user_mu = nn.Linear(user_encoder_structure[-1], k)  # mu\n","        self.user_std = nn.Linear(user_encoder_structure[-1], k)\n","\n","        # Item Encoder\n","        self.item_encoder = nn.Sequential()\n","        for i in range(len(item_encoder_structure) - 1):\n","            self.item_encoder.add_module(\n","                \"fc{}\".format(i),\n","                nn.Linear(item_encoder_structure[i], item_encoder_structure[i + 1]),\n","            )\n","            self.item_encoder.add_module(\"act{}\".format(i), self.act_fn)\n","        self.item_mu = nn.Linear(item_encoder_structure[-1], k)  # mu\n","        self.item_std = nn.Linear(item_encoder_structure[-1], k)\n","\n","    def to(self, device):\n","        self.beta = self.beta.to(device=device)\n","        self.theta = self.theta.to(device=device)\n","        self.mu_beta = self.mu_beta.to(device=device)\n","        self.mu_theta = self.mu_theta.to(device=device)\n","        return super(BiVAE, self).to(device)\n","\n","    def encode_user_prior(self, x):\n","        h = self.user_prior_encoder(x)\n","        return h\n","\n","    def encode_item_prior(self, x):\n","        h = self.item_prior_encoder(x)\n","        return h\n","\n","    def encode_user(self, x):\n","        h = self.user_encoder(x)\n","        return self.user_mu(h), torch.sigmoid(self.user_std(h))\n","\n","    def encode_item(self, x):\n","        h = self.item_encoder(x)\n","        return self.item_mu(h), torch.sigmoid(self.item_std(h))\n","\n","    def decode_user(self, theta, beta):\n","        h = theta.mm(beta.t())\n","        return torch.sigmoid(h)\n","\n","    def decode_item(self, theta, beta):\n","        h = beta.mm(theta.t())\n","        return torch.sigmoid(h)\n","\n","    def reparameterize(self, mu, std):\n","        eps = torch.randn_like(mu)\n","        return mu + eps * std\n","\n","    def forward(self, x, user=True, beta=None, theta=None):\n","\n","        if user:\n","            mu, std = self.encode_user(x)\n","            theta = self.reparameterize(mu, std)\n","            return theta, self.decode_user(theta, beta), mu, std\n","        else:\n","            mu, std = self.encode_item(x)\n","            beta = self.reparameterize(mu, std)\n","            return beta, self.decode_item(theta, beta), mu, std\n","\n","    def loss(self, x, x_, mu, mu_prior, std, kl_beta):\n","        # Likelihood\n","        ll_choices = {\n","            \"bern\": x * torch.log(x_ + EPS) + (1 - x) * torch.log(1 - x_ + EPS),\n","            \"gaus\": -(x - x_) ** 2,\n","            \"pois\": x * torch.log(x_ + EPS) - x_,\n","        }\n","\n","        ll = ll_choices.get(self.likelihood, None)\n","        if ll is None:\n","            raise ValueError(\"Supported likelihoods: {}\".format(ll_choices.keys()))\n","\n","        ll = torch.sum(ll, dim=1)\n","\n","        # KL term\n","        kld = -0.5 * (1 + 2.0 * torch.log(std) - (mu - mu_prior).pow(2) - std.pow(2))\n","        kld = torch.sum(kld, dim=1)\n","\n","        return torch.mean(kl_beta * kld - ll)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Learn"]},{"cell_type":"code","execution_count":104,"metadata":{"cellView":"form","executionInfo":{"elapsed":324,"status":"ok","timestamp":1705994231535,"user":{"displayName":"Narada Wijerathne","userId":"01570151137951130679"},"user_tz":-330},"id":"h_qOW0igV_qB"},"outputs":[],"source":["\n","def learn(\n","    bivae,\n","    train_set,\n","    n_epochs,\n","    user_batch_size,\n","    item_batch_size,\n","    user_learn_rate,\n","    item_learn_rate,\n","    beta_kl,\n","    verbose,\n","    plot_loss = False,\n","    device=torch.device(\"cpu\"),\n","    dtype=torch.float32,\n","):\n","    user_params = it.chain(\n","        bivae.user_encoder.parameters(),\n","        bivae.user_mu.parameters(),\n","        bivae.user_std.parameters(),\n","    )\n","\n","    item_params = it.chain(\n","        bivae.item_encoder.parameters(),\n","        bivae.item_mu.parameters(),\n","        bivae.item_std.parameters(),\n","    )\n","\n","    if bivae.cap_priors.get(\"user\", False):\n","        user_params = it.chain(user_params, bivae.user_prior_encoder.parameters())\n","        user_features = train_set.user_feature.features[: train_set.num_users]\n","\n","    if bivae.cap_priors.get(\"item\", False):\n","        item_params = it.chain(item_params, bivae.item_prior_encoder.parameters())\n","        item_features = train_set.item_feature.features[: train_set.num_items]\n","\n","    u_optimizer = torch.optim.Adam(params=user_params, lr=user_learn_rate)\n","    i_optimizer = torch.optim.Adam(params=item_params, lr=item_learn_rate)\n","\n","    x = train_set.matrix.copy()\n","    x.data = np.ones_like(x.data)  # Binarize data\n","    tx = x.transpose()\n","\n","    progress_bar = trange(1, n_epochs + 1, disable=not verbose)\n","\n","    u_loss_list = []\n","    i_loss_list = []\n","    for _ in progress_bar:\n","\n","        # item side\n","        i_sum_loss = 0.0\n","        i_count = 0\n","        for i_ids in train_set.item_iter(item_batch_size, shuffle=False):\n","            i_batch = tx[i_ids, :]\n","            i_batch = i_batch.A\n","            i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n","\n","            # Reconstructed batch\n","            beta, i_batch_, i_mu, i_std = bivae(i_batch, user=False, theta=bivae.theta)\n","\n","            i_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n","            if bivae.cap_priors.get(\"item\", False):\n","                i_batch_f = item_features[i_ids]\n","                i_batch_f = torch.tensor(i_batch_f, dtype=dtype, device=device)\n","                i_mu_prior = bivae.encode_item_prior(i_batch_f)\n","\n","            i_loss = bivae.loss(i_batch, i_batch_, i_mu, i_mu_prior, i_std, beta_kl)\n","            i_optimizer.zero_grad()\n","            i_loss.backward()\n","            i_optimizer.step()\n","\n","            i_sum_loss += i_loss.data.item()\n","            i_count += len(i_batch)\n","\n","            beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n","\n","            bivae.beta.data[i_ids] = beta.data\n","            bivae.mu_beta.data[i_ids] = i_mu.data\n","\n","\n","        # user side\n","        u_sum_loss = 0.0\n","        u_count = 0\n","        for u_ids in train_set.user_iter(user_batch_size, shuffle=False):\n","            u_batch = x[u_ids, :]\n","            u_batch = u_batch.A\n","            u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n","\n","            # Reconstructed batch\n","            theta, u_batch_, u_mu, u_std = bivae(u_batch, user=True, beta=bivae.beta)\n","\n","            u_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n","            if bivae.cap_priors.get(\"user\", False):\n","                u_batch_f = user_features[u_ids]\n","                u_batch_f = torch.tensor(u_batch_f, dtype=dtype, device=device)\n","                u_mu_prior = bivae.encode_user_prior(u_batch_f)\n","\n","            u_loss = bivae.loss(u_batch, u_batch_, u_mu, u_mu_prior, u_std, beta_kl)\n","            u_optimizer.zero_grad()\n","            u_loss.backward()\n","            u_optimizer.step()\n","\n","            u_sum_loss += u_loss.data.item()\n","            u_count += len(u_batch)\n","\n","            theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n","            bivae.theta.data[u_ids] = theta.data\n","            bivae.mu_theta.data[u_ids] = u_mu.data\n","\n","        progress_bar.set_postfix(\n","            loss_i=(i_sum_loss / i_count), loss_u=(u_sum_loss / (u_count))\n","        )\n","\n","        u_loss_list.append(u_sum_loss / u_count)\n","\n","        i_loss_list.append(i_sum_loss / i_count)\n","\n","\n","\n","\n","    # infer mu_beta\n","    for i_ids in train_set.item_iter(item_batch_size, shuffle=False):\n","        i_batch = tx[i_ids, :]\n","        i_batch = i_batch.A\n","        i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n","\n","        beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n","        bivae.mu_beta.data[i_ids] = i_mu.data\n","\n","    # infer mu_theta\n","    for u_ids in train_set.user_iter(user_batch_size, shuffle=False):\n","        u_batch = x[u_ids, :]\n","        u_batch = u_batch.A\n","        u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n","\n","        theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n","        bivae.mu_theta.data[u_ids] = u_mu.data\n","\n","    #plotting losses\n","    x = list(range(1, n_epochs+1))\n","\n","    if plot_loss:\n","      plt.figure(figsize=(10, 5))\n","      plt.plot(x, u_loss_list, label = 'u_loss')\n","      plt.plot(x, i_loss_list, label = 'i_loss')\n","      plt.legend()\n","      plt.show()\n","    return bivae"]},{"cell_type":"markdown","metadata":{"id":"oxLK4GoxUUnV"},"source":["## Recommender"]},{"cell_type":"code","execution_count":105,"metadata":{"cellView":"form","id":"GhpVvWD0WAbQ"},"outputs":[],"source":["class BiVAECF(Recommender):\n","    \"\"\"Bilateral Variational AutoEncoder for Collaborative Filtering.\n","    Parameters\n","    ----------\n","    k: int, optional, default: 10\n","        The dimension of the stochastic user ``theta'' and item ``beta'' factors.\n","    encoder_structure: list, default: [20]\n","        The number of neurons per layer of the user and item encoders for BiVAE.\n","        For example, encoder_structure = [20], the user (item) encoder structure will be [num_items, 20, k] ([num_users, 20, k]).\n","    act_fn: str, default: 'tanh'\n","        Name of the activation function used between hidden layers of the auto-encoder.\n","        Supported functions: ['sigmoid', 'tanh', 'elu', 'relu', 'relu6']\n","    likelihood: str, default: 'pois'\n","        The likelihood function used for modeling the observations.\n","        Supported choices:\n","        bern: Bernoulli likelihood\n","        gaus: Gaussian likelihood\n","        pois: Poisson likelihood\n","    n_epochs: int, optional, default: 100\n","        The number of epochs for SGD.\n","    batch_size: int, optional, default: 100\n","        The batch size.\n","    learning_rate: float, optional, default: 0.001\n","        The learning rate for Adam.\n","    beta_kl: float, optional, default: 1.0\n","        The weight of the KL terms as in beta-VAE.\n","    cap_priors: dict, optional, default: {\"user\":False, \"item\":False}\n","        When {\"user\":True, \"item\":True}, CAP priors are used (see BiVAE paper for details),\\\n","        otherwise the standard Normal is used as a Prior over the user and item latent variables.\n","    name: string, optional, default: 'BiVAECF'\n","        The name of the recommender model.\n","    trainable: boolean, optional, default: True\n","        When False, the model is not trained and Cornac assumes that the model is already \\\n","        pre-trained.\n","    verbose: boolean, optional, default: False\n","        When True, some running logs are displayed.\n","    seed: int, optional, default: None\n","        Random seed for parameters initialization.\n","    use_gpu: boolean, optional, default: True\n","        If True and your system supports CUDA then training is performed on GPUs.\n","    References\n","    ----------\n","    * Quoc-Tuan Truong, Aghiles Salah, Hady W. Lauw. \" Bilateral Variational Autoencoder for Collaborative Filtering.\"\n","    ACM International Conference on Web Search and Data Mining (WSDM). 2021.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        name=\"BiVAECF\",\n","        k=10,\n","        user_encoder_structure=[20],\n","        item_encoder_structure = [20],\n","        act_fn=\"tanh\",\n","        likelihood=\"pois\",\n","        n_epochs=100,\n","        user_batch_size=100,\n","        item_batch_size = 100,\n","        user_learning_rate=0.001,\n","        item_learning_rate=0.001,\n","        beta_kl=1.0,\n","        cap_priors={\"user\": False, \"item\": False},\n","        trainable=True,\n","        verbose=False,\n","        seed=None,\n","        use_gpu=True,\n","        plot_loss = False,\n","    ):\n","        Recommender.__init__(self, name=name, trainable=trainable, verbose=verbose)\n","        self.k = k\n","        self.user_encoder_structure = user_encoder_structure\n","        self.item_encoder_structure = item_encoder_structure\n","        self.act_fn = act_fn\n","        self.likelihood = likelihood\n","        self.user_batch_size = user_batch_size\n","        self.item_batch_size = item_batch_size\n","        self.n_epochs = n_epochs\n","        self.user_learning_rate = user_learning_rate\n","        self.item_learning_rate = item_learning_rate\n","        self.beta_kl = beta_kl\n","        self.cap_priors = cap_priors\n","        self.seed = seed\n","        self.use_gpu = use_gpu\n","        self.plot_loss = plot_loss\n","\n","    def fit(self, train_set, val_set=None):\n","        \"\"\"Fit the model to observations.\n","        Parameters\n","        ----------\n","        train_set: :obj:`cornac.data.Dataset`, required\n","            User-Item preference data as well as additional modalities.\n","        val_set: :obj:`cornac.data.Dataset`, optional, default: None\n","            User-Item preference data for model selection purposes (e.g., early stopping).\n","        Returns\n","        -------\n","        self : object\n","        \"\"\"\n","        Recommender.fit(self, train_set, val_set)\n","\n","        self.device = (\n","            torch.device(\"cuda:0\")\n","            if (self.use_gpu and torch.cuda.is_available())\n","            else torch.device(\"cpu\")\n","        )\n","\n","        if self.trainable:\n","            feature_dim = {\"user\": None, \"item\": None}\n","            if self.cap_priors.get(\"user\", False):\n","                if train_set.user_feature is None:\n","                    raise ValueError(\n","                        \"CAP priors for users is set to True but no user features are provided\"\n","                    )\n","                else:\n","                    feature_dim[\"user\"] = train_set.user_feature.feature_dim\n","\n","            if self.cap_priors.get(\"item\", False):\n","                if train_set.item_feature is None:\n","                    raise ValueError(\n","                        \"CAP priors for items is set to True but no item features are provided\"\n","                    )\n","                else:\n","                    feature_dim[\"item\"] = train_set.item_feature.feature_dim\n","\n","            if self.seed is not None:\n","                torch.manual_seed(self.seed)\n","                torch.cuda.manual_seed(self.seed)\n","\n","            if not hasattr(self, \"bivaecf\"):\n","                num_items = train_set.matrix.shape[1]\n","                num_users = train_set.matrix.shape[0]\n","                self.bivae = BiVAE(\n","                    k=self.k,\n","                    #changes\n","                    user_encoder_structure=[num_items] + self.user_encoder_structure,\n","                    item_encoder_structure=[num_users] + self.item_encoder_structure,\n","                    #changes end\n","                    act_fn=self.act_fn,\n","                    likelihood=self.likelihood,\n","                    cap_priors=self.cap_priors,\n","                    feature_dim=feature_dim,\n","                    user_batch_size=self.user_batch_size,\n","                    item_batch_size = self.item_batch_size\n","                ).to(self.device)\n","\n","            learn(\n","                self.bivae,\n","                self.train_set,\n","                n_epochs=self.n_epochs,\n","                user_batch_size=self.user_batch_size,\n","                item_batch_size = self.user_batch_size,\n","                user_learn_rate=self.user_learning_rate,\n","                item_learn_rate = self.item_learning_rate,\n","                beta_kl=self.beta_kl,\n","                verbose=self.verbose,\n","                device=self.device,\n","                plot_loss = self.plot_loss,\n","            )\n","\n","        elif self.verbose:\n","            print(\"%s is trained already (trainable = False)\" % (self.name))\n","\n","        return self\n","\n","    def score(self, user_idx, item_idx=None):\n","        \"\"\"Predict the scores/ratings of a user for an item.\n","        Parameters\n","        ----------\n","        user_idx: int, required\n","            The index of the user for whom to perform score prediction.\n","        item_idx: int, optional, default: None\n","            The index of the item for which to perform score prediction.\n","            If None, scores for all known items will be returned.\n","        Returns\n","        -------\n","        res : A scalar or a Numpy array\n","            Relative scores that the user gives to the item or to all known items\n","        \"\"\"\n","\n","        if item_idx is None:\n","            if self.train_set.is_unk_user(user_idx):\n","                raise ScoreException(\n","                    \"Can't make score prediction for (user_id=%d)\" % user_idx\n","                )\n","\n","            theta_mu_u = self.bivae.mu_theta[user_idx].view(1, -1)\n","            # theta_u = self.bivae.theta[user_idx].view(1, -1)\n","            beta = self.bivae.mu_beta\n","            known_item_scores = (\n","                self.bivae.decode_user(theta_mu_u, beta).cpu().numpy().ravel()\n","                # self.bivae.decode_user(theta, beta).cpu().detach().numpy().ravel()\n","            )\n","\n","            return known_item_scores\n","        else:\n","            if self.train_set.is_unk_user(user_idx) or self.train_set.is_unk_item(\n","                item_idx\n","            ):\n","                raise ScoreException(\n","                    \"Can't make score prediction for (user_id=%d, item_id=%d)\"\n","                    % (user_idx, item_idx)\n","                )\n","\n","            theta_mu_u = self.bivae.mu_theta[user_idx].view(1, -1)\n","            # theta_u = self.bivae.theta[user_idx].view(1, -1)\n","            beta_i = self.bivae.mu_beta[item_idx].view(1, -1)\n","            pred = self.bivae.decode_user(theta_mu_u, beta_i).cpu().numpy().ravel()\n","            # pred = self.bivae.decode_user(theta_u, beta).cpu().detach().numpy().ravel()\n","\n","            pred = scale(\n","                pred, self.train_set.min_rating, self.train_set.max_rating, 0.0, 1.0\n","            )\n","\n","            return pred"]},{"cell_type":"markdown","metadata":{},"source":["# cornac 1.18 BiVAE"]},{"cell_type":"markdown","metadata":{},"source":["## bivae"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["# Copyright 2018 The Cornac Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ============================================================================\n","\n","import itertools as it\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import trange\n","\n","\n","EPS = 1e-10\n","\n","ACT = {\n","    \"sigmoid\": nn.Sigmoid(),\n","    \"tanh\": nn.Tanh(),\n","    \"elu\": nn.ELU(),\n","    \"relu\": nn.ReLU(),\n","    \"relu6\": nn.ReLU6(),\n","}\n","\n","\n","class BiVAE(nn.Module):\n","    def __init__(\n","        self,\n","        k,\n","        user_encoder_structure,\n","        item_encoder_structure,\n","        act_fn,\n","        likelihood,\n","        cap_priors,\n","        feature_dim,\n","        batch_size,\n","    ):\n","        super(BiVAE, self).__init__()\n","\n","        self.mu_theta = torch.zeros((item_encoder_structure[0], k))  # n_users*k\n","        self.mu_beta = torch.zeros((user_encoder_structure[0], k))  # n_items*k\n","\n","        self.theta = torch.randn(item_encoder_structure[0], k) * 0.01\n","        self.beta = torch.randn(user_encoder_structure[0], k) * 0.01\n","        torch.nn.init.kaiming_uniform_(self.theta, a=np.sqrt(5))\n","\n","        self.likelihood = likelihood\n","        self.act_fn = ACT.get(act_fn, None)\n","        if self.act_fn is None:\n","            raise ValueError(\"Supported act_fn: {}\".format(ACT.keys()))\n","\n","        self.cap_priors = cap_priors\n","        if self.cap_priors.get(\"user\", False):\n","            self.user_prior_encoder = nn.Linear(feature_dim.get(\"user\"), k)\n","        if self.cap_priors.get(\"item\", False):\n","            self.item_prior_encoder = nn.Linear(feature_dim.get(\"item\"), k)\n","\n","        # User Encoder\n","        self.user_encoder = nn.Sequential()\n","        for i in range(len(user_encoder_structure) - 1):\n","            self.user_encoder.add_module(\n","                \"fc{}\".format(i),\n","                nn.Linear(user_encoder_structure[i], user_encoder_structure[i + 1]),\n","            )\n","            self.user_encoder.add_module(\"act{}\".format(i), self.act_fn)\n","        self.user_mu = nn.Linear(user_encoder_structure[-1], k)  # mu\n","        self.user_std = nn.Linear(user_encoder_structure[-1], k)\n","\n","        # Item Encoder\n","        self.item_encoder = nn.Sequential()\n","        for i in range(len(item_encoder_structure) - 1):\n","            self.item_encoder.add_module(\n","                \"fc{}\".format(i),\n","                nn.Linear(item_encoder_structure[i], item_encoder_structure[i + 1]),\n","            )\n","            self.item_encoder.add_module(\"act{}\".format(i), self.act_fn)\n","        self.item_mu = nn.Linear(item_encoder_structure[-1], k)  # mu\n","        self.item_std = nn.Linear(item_encoder_structure[-1], k)\n","\n","    def to(self, device):\n","        self.beta = self.beta.to(device=device)\n","        self.theta = self.theta.to(device=device)\n","        self.mu_beta = self.mu_beta.to(device=device)\n","        self.mu_theta = self.mu_theta.to(device=device)\n","        return super(BiVAE, self).to(device)\n","\n","    def encode_user_prior(self, x):\n","        h = self.user_prior_encoder(x)\n","        return h\n","\n","    def encode_item_prior(self, x):\n","        h = self.item_prior_encoder(x)\n","        return h\n","\n","    def encode_user(self, x):\n","        h = self.user_encoder(x)\n","        return self.user_mu(h), torch.sigmoid(self.user_std(h))\n","\n","    def encode_item(self, x):\n","        h = self.item_encoder(x)\n","        return self.item_mu(h), torch.sigmoid(self.item_std(h))\n","\n","    def decode_user(self, theta, beta):\n","        h = theta.mm(beta.t())\n","        return torch.sigmoid(h)\n","\n","    def decode_item(self, theta, beta):\n","        h = beta.mm(theta.t())\n","        return torch.sigmoid(h)\n","\n","    def reparameterize(self, mu, std):\n","        eps = torch.randn_like(mu)\n","        return mu + eps * std\n","\n","    def forward(self, x, user=True, beta=None, theta=None):\n","\n","        if user:\n","            mu, std = self.encode_user(x)\n","            theta = self.reparameterize(mu, std)\n","            return theta, self.decode_user(theta, beta), mu, std\n","        else:\n","            mu, std = self.encode_item(x)\n","            beta = self.reparameterize(mu, std)\n","            return beta, self.decode_item(theta, beta), mu, std\n","\n","    def loss(self, x, x_, mu, mu_prior, std, kl_beta):\n","        # Likelihood\n","        ll_choices = {\n","            \"bern\": x * torch.log(x_ + EPS) + (1 - x) * torch.log(1 - x_ + EPS),\n","            \"gaus\": -(x - x_) ** 2,\n","            \"pois\": x * torch.log(x_ + EPS) - x_,\n","        }\n","\n","        ll = ll_choices.get(self.likelihood, None)\n","        if ll is None:\n","            raise ValueError(\"Supported likelihoods: {}\".format(ll_choices.keys()))\n","\n","        ll = torch.sum(ll, dim=1)\n","\n","        # KL term\n","        kld = -0.5 * (1 + 2.0 * torch.log(std) - (mu - mu_prior).pow(2) - std.pow(2))\n","        kld = torch.sum(kld, dim=1)\n","\n","        return torch.mean(kl_beta * kld - ll)\n","\n","\n","def learn(\n","    bivae,\n","    train_set,\n","    n_epochs,\n","    batch_size,\n","    learn_rate,\n","    beta_kl,\n","    verbose,\n","    device=torch.device(\"cpu\"),\n","    dtype=torch.float32,\n","):\n","    user_params = it.chain(\n","        bivae.user_encoder.parameters(),\n","        bivae.user_mu.parameters(),\n","        bivae.user_std.parameters(),\n","    )\n","\n","    item_params = it.chain(\n","        bivae.item_encoder.parameters(),\n","        bivae.item_mu.parameters(),\n","        bivae.item_std.parameters(),\n","    )\n","\n","    if bivae.cap_priors.get(\"user\", False):\n","        user_params = it.chain(user_params, bivae.user_prior_encoder.parameters())\n","        user_features = train_set.user_feature.features[: train_set.num_users]\n","\n","    if bivae.cap_priors.get(\"item\", False):\n","        item_params = it.chain(item_params, bivae.item_prior_encoder.parameters())\n","        item_features = train_set.item_feature.features[: train_set.num_items]\n","\n","    u_optimizer = torch.optim.Adam(params=user_params, lr=learn_rate)\n","    i_optimizer = torch.optim.Adam(params=item_params, lr=learn_rate)\n","\n","    x = train_set.matrix.copy()\n","    x.data = np.ones_like(x.data)  # Binarize data\n","    tx = x.transpose()\n","\n","    progress_bar = trange(1, n_epochs + 1, disable=not verbose)\n","    for _ in progress_bar:\n","        # item side\n","        i_sum_loss = 0.0\n","        i_count = 0\n","        for i_ids in train_set.item_iter(batch_size, shuffle=False):\n","            i_batch = tx[i_ids, :]\n","            i_batch = i_batch.A\n","            i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n","\n","            # Reconstructed batch\n","            beta, i_batch_, i_mu, i_std = bivae(i_batch, user=False, theta=bivae.theta)\n","\n","            i_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n","            if bivae.cap_priors.get(\"item\", False):\n","                i_batch_f = item_features[i_ids]\n","                i_batch_f = torch.tensor(i_batch_f, dtype=dtype, device=device)\n","                i_mu_prior = bivae.encode_item_prior(i_batch_f)\n","\n","            i_loss = bivae.loss(i_batch, i_batch_, i_mu, i_mu_prior, i_std, beta_kl)\n","            i_optimizer.zero_grad()\n","            i_loss.backward()\n","            i_optimizer.step()\n","\n","            i_sum_loss += i_loss.data.item()\n","            i_count += len(i_batch)\n","\n","            beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n","\n","            bivae.beta.data[i_ids] = beta.data\n","            bivae.mu_beta.data[i_ids] = i_mu.data\n","\n","        # user side\n","        u_sum_loss = 0.0\n","        u_count = 0\n","        for u_ids in train_set.user_iter(batch_size, shuffle=False):\n","            u_batch = x[u_ids, :]\n","            u_batch = u_batch.A\n","            u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n","\n","            # Reconstructed batch\n","            theta, u_batch_, u_mu, u_std = bivae(u_batch, user=True, beta=bivae.beta)\n","\n","            u_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n","            if bivae.cap_priors.get(\"user\", False):\n","                u_batch_f = user_features[u_ids]\n","                u_batch_f = torch.tensor(u_batch_f, dtype=dtype, device=device)\n","                u_mu_prior = bivae.encode_user_prior(u_batch_f)\n","\n","            u_loss = bivae.loss(u_batch, u_batch_, u_mu, u_mu_prior, u_std, beta_kl)\n","            u_optimizer.zero_grad()\n","            u_loss.backward()\n","            u_optimizer.step()\n","\n","            u_sum_loss += u_loss.data.item()\n","            u_count += len(u_batch)\n","\n","            theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n","            bivae.theta.data[u_ids] = theta.data\n","            bivae.mu_theta.data[u_ids] = u_mu.data\n","\n","            progress_bar.set_postfix(\n","                loss_i=(i_sum_loss / i_count), loss_u=(u_sum_loss / (u_count))\n","            )\n","\n","    # infer mu_beta\n","    for i_ids in train_set.item_iter(batch_size, shuffle=False):\n","        i_batch = tx[i_ids, :]\n","        i_batch = i_batch.A\n","        i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n","\n","        beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n","        bivae.mu_beta.data[i_ids] = i_mu.data\n","\n","    # infer mu_theta\n","    for u_ids in train_set.user_iter(batch_size, shuffle=False):\n","        u_batch = x[u_ids, :]\n","        u_batch = u_batch.A\n","        u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n","\n","        theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n","        bivae.mu_theta.data[u_ids] = u_mu.data\n","\n","    return bivae"]},{"cell_type":"markdown","metadata":{},"source":["## BiVAECF recommender"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["class BiVAECF(Recommender, ANNMixin):\n","    \"\"\"Bilateral Variational AutoEncoder for Collaborative Filtering.\n","\n","    Parameters\n","    ----------\n","    k: int, optional, default: 10\n","        The dimension of the stochastic user ``theta'' and item ``beta'' factors.\n","\n","    encoder_structure: list, default: [20]\n","        The number of neurons per layer of the user and item encoders for BiVAE.\n","        For example, encoder_structure = [20], the user (item) encoder structure will be [num_items, 20, k] ([num_users, 20, k]).\n","\n","    act_fn: str, default: 'tanh'\n","        Name of the activation function used between hidden layers of the auto-encoder.\n","        Supported functions: ['sigmoid', 'tanh', 'elu', 'relu', 'relu6']\n","\n","    likelihood: str, default: 'pois'\n","        The likelihood function used for modeling the observations.\n","        Supported choices:\n","\n","        bern: Bernoulli likelihood\n","        gaus: Gaussian likelihood\n","        pois: Poisson likelihood\n","\n","    n_epochs: int, optional, default: 100\n","        The number of epochs for SGD.\n","\n","    batch_size: int, optional, default: 100\n","        The batch size.\n","\n","    learning_rate: float, optional, default: 0.001\n","        The learning rate for Adam.\n","\n","    beta_kl: float, optional, default: 1.0\n","        The weight of the KL terms as in beta-VAE.\n","\n","    cap_priors: dict, optional, default: {\"user\":False, \"item\":False}\n","        When {\"user\":True, \"item\":True}, CAP priors are used (see BiVAE paper for details),\\\n","        otherwise the standard Normal is used as a Prior over the user and item latent variables.\n","\n","    name: string, optional, default: 'BiVAECF'\n","        The name of the recommender model.\n","\n","    trainable: boolean, optional, default: True\n","        When False, the model is not trained and Cornac assumes that the model is already \\\n","        pre-trained.\n","\n","    verbose: boolean, optional, default: False\n","        When True, some running logs are displayed.\n","\n","    seed: int, optional, default: None\n","        Random seed for parameters initialization.\n","\n","    use_gpu: boolean, optional, default: True\n","        If True and your system supports CUDA then training is performed on GPUs.\n","\n","    References\n","    ----------\n","    * Quoc-Tuan Truong, Aghiles Salah, Hady W. Lauw. \" Bilateral Variational Autoencoder for Collaborative Filtering.\"\n","    ACM International Conference on Web Search and Data Mining (WSDM). 2021.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        name=\"BiVAECF\",\n","        k=10,\n","        user_encoder_structure=[20],\n","        item_encoder_structure = [20],\n","        act_fn=\"tanh\",\n","        likelihood=\"pois\",\n","        n_epochs=100,\n","        batch_size=100,\n","        learning_rate=0.001,\n","        beta_kl=1.0,\n","        cap_priors={\"user\": False, \"item\": False},\n","        trainable=True,\n","        verbose=False,\n","        seed=None,\n","        use_gpu=True,\n","    ):\n","        Recommender.__init__(self, name=name, trainable=trainable, verbose=verbose)\n","        self.k = k\n","        self.user_encoder_structure = user_encoder_structure\n","        self.item_encoder_structure = item_encoder_structure\n","        self.act_fn = act_fn\n","        self.likelihood = likelihood\n","        self.batch_size = batch_size\n","        self.n_epochs = n_epochs\n","        self.learning_rate = learning_rate\n","        self.beta_kl = beta_kl\n","        self.cap_priors = cap_priors\n","        self.seed = seed\n","        self.use_gpu = use_gpu\n","\n","\n","    def fit(self, train_set, val_set=None):\n","        \"\"\"Fit the model to observations.\n","\n","        Parameters\n","        ----------\n","        train_set: :obj:`cornac.data.Dataset`, required\n","            User-Item preference data as well as additional modalities.\n","\n","        val_set: :obj:`cornac.data.Dataset`, optional, default: None\n","            User-Item preference data for model selection purposes (e.g., early stopping).\n","\n","        Returns\n","        -------\n","        self : object\n","        \"\"\"\n","        Recommender.fit(self, train_set, val_set)\n","\n","        import torch\n","        # from .bivae import BiVAE, learn\n","        self.device = (\n","            torch.device(\"cuda:0\")\n","            if (self.use_gpu and torch.cuda.is_available())\n","            else torch.device(\"cpu\")\n","        )\n","\n","        if self.trainable:\n","            feature_dim = {\"user\": None, \"item\": None}\n","            if self.cap_priors.get(\"user\", False):\n","                if train_set.user_feature is None:\n","                    raise ValueError(\n","                        \"CAP priors for users is set to True but no user features are provided\"\n","                    )\n","                else:\n","                    feature_dim[\"user\"] = train_set.user_feature.feature_dim\n","\n","            if self.cap_priors.get(\"item\", False):\n","                if train_set.item_feature is None:\n","                    raise ValueError(\n","                        \"CAP priors for items is set to True but no item features are provided\"\n","                    )\n","                else:\n","                    feature_dim[\"item\"] = train_set.item_feature.feature_dim\n","\n","            if self.seed is not None:\n","                torch.manual_seed(self.seed)\n","                torch.cuda.manual_seed(self.seed)\n","\n","            if not hasattr(self, \"bivae\"):\n","                num_items = train_set.matrix.shape[1]\n","                num_users = train_set.matrix.shape[0]\n","                self.bivae = BiVAE(\n","                    k=self.k,\n","                    user_encoder_structure=[num_items] + self.user_encoder_structure,\n","                    item_encoder_structure=[num_users] + self.item_encoder_structure,\n","                    act_fn=self.act_fn,\n","                    likelihood=self.likelihood,\n","                    cap_priors=self.cap_priors,\n","                    feature_dim=feature_dim,\n","                    batch_size=self.batch_size,\n","                ).to(self.device)\n","\n","            learn(\n","                self.bivae,\n","                train_set,\n","                n_epochs=self.n_epochs,\n","                batch_size=self.batch_size,\n","                learn_rate=self.learning_rate,\n","                beta_kl=self.beta_kl,\n","                verbose=self.verbose,\n","                device=self.device,\n","            )\n","        elif self.verbose:\n","            print(\"%s is trained already (trainable = False)\" % (self.name))\n","\n","        return self\n","\n","\n","    def score(self, user_idx, item_idx=None):\n","        \"\"\"Predict the scores/ratings of a user for an item.\n","\n","        Parameters\n","        ----------\n","        user_idx: int, required\n","            The index of the user for whom to perform score prediction.\n","\n","        item_idx: int, optional, default: None\n","            The index of the item for which to perform score prediction.\n","            If None, scores for all known items will be returned.\n","\n","        Returns\n","        -------\n","        res : A scalar or a Numpy array\n","            Relative scores that the user gives to the item or to all known items\n","\n","        \"\"\"\n","        if self.is_unknown_user(user_idx):\n","            raise ScoreException(\"Can't make score prediction for user %d\" % user_idx)\n","\n","        if item_idx is not None and self.is_unknown_item(item_idx):\n","            raise ScoreException(\"Can't make score prediction for item %d\" % item_idx)\n","\n","        if item_idx is None:\n","            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n","            beta = self.bivae.mu_beta\n","            return self.bivae.decode_user(theta_u, beta).cpu().numpy().ravel()\n","        else:\n","            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n","            beta_i = self.bivae.mu_beta[item_idx].view(1, -1)\n","            pred = self.bivae.decode_user(theta_u, beta_i).cpu().numpy().ravel()\n","            return scale(pred, self.min_rating, self.max_rating, 0.0, 1.0)\n","\n","\n","    def get_vector_measure(self):\n","        \"\"\"Getting a valid choice of vector measurement in ANNMixin._measures.\n","\n","        Returns\n","        -------\n","        measure: MEASURE_DOT\n","            Dot product aka. inner product\n","        \"\"\"\n","        return MEASURE_DOT\n","\n","\n","    def get_user_vectors(self):\n","        \"\"\"Getting a matrix of user vectors serving as query for ANN search.\n","\n","        Returns\n","        -------\n","        out: numpy.array\n","            Matrix of user vectors for all users available in the model.\n","        \"\"\"\n","        user_vectors = self.bivae.mu_theta.detach().cpu().numpy()\n","        return user_vectors\n","\n","\n","    def get_item_vectors(self):\n","        \"\"\"Getting a matrix of item vectors used for building the index for ANN search.\n","\n","        Returns\n","        -------\n","        out: numpy.array\n","            Matrix of item vectors for all items available in the model.\n","        \"\"\"\n","        item_vectors = self.bivae.mu_beta.detach().cpu().numpy()\n","        return item_vectors\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Functions"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["def predict_ranking(\n","    model,\n","    data,\n","    usercol='userID',\n","    itemcol='itemID',\n","    predcol='pred',\n","    remove_seen=False,\n","):\n","    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n","    It can be used for computing ranking metrics like NDCG.\n","\n","    Args:\n","        model (cornac.models.Recommender): A recommender model from Cornac\n","        data (pandas.DataFrame): The data from which to get the users and items\n","        usercol (str): Name of the user column\n","        itemcol (str): Name of the item column\n","        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n","\n","    Returns:\n","        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n","    \"\"\"\n","    users, items, preds = [], [], []\n","    item = list(model.iid_map.keys())\n","    for uid, user_idx in model.uid_map.items():\n","        user = [uid] * len(item)\n","        users.extend(user)\n","        items.extend(item)\n","        preds.extend(model.score(user_idx).tolist())\n","\n","    all_predictions = pd.DataFrame(\n","        data={usercol: users, itemcol: items, predcol: preds}\n","    )\n","\n","    if remove_seen:\n","        tempdf = pd.concat(\n","            [\n","                data[[usercol, itemcol]],\n","                pd.DataFrame(\n","                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n","                ),\n","            ],\n","            axis=1,\n","        )\n","        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n","        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n","    else:\n","        return all_predictions"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["def predict_ranking_user(\n","    model,\n","    data,\n","    user_id,\n","    usercol='userID',\n","    itemcol='itemID',\n","    predcol='pred',\n","    remove_seen=False,\n","):\n","    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n","    It can be used for computing ranking metrics like NDCG.\n","\n","    Args:\n","        model (cornac.models.Recommender): A recommender model from Cornac\n","        data (pandas.DataFrame): The data from which to get the users and items\n","        usercol (str): Name of the user column\n","        itemcol (str): Name of the item column\n","        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n","\n","    Returns:\n","        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n","    \"\"\"\n","    users, items, preds = [], [], []\n","    item = list(model.iid_map.keys())\n","    # reverse_uid_map = {val : key for key,val in dict(model_.uid_map).items()}\n","    user_idx = dict(model_.uid_map).get(user_id)\n","\n","    user_data = data.loc[data[usercol] == user_id]\n","\n","    # user = [uid] * len(item)\n","    # users.extend(user)\n","    items.extend(item)\n","    preds.extend(model.score(user_idx).tolist())\n","\n","    all_predictions = pd.DataFrame(\n","        data={itemcol: items, predcol: preds}\n","    )\n","\n","    if remove_seen:\n","        tempdf = pd.concat(\n","            [\n","                user_data[[itemcol]],\n","                pd.DataFrame(\n","                    data=np.ones(user_data.shape[0]), columns=[\"dummycol\"], index=user_data.index\n","                ),\n","            ],\n","            axis=1,\n","        )\n","        merged = pd.merge(tempdf, all_predictions, on=[itemcol], how=\"outer\")\n","        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n","    else:\n","        return all_predictions"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["def score_new_user(\n","        symbols, \n","        model_,\n","        itemcol='itemID',\n","        predcol='pred',\n","        remove_seen=False,\n","        ):\n","\n","\n","    user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n","    user_vec = np.zeros(len(model_.iid_map.keys()))\n","    user_vec[user_symbol_idx] =1\n","    \n","    user_encoder = model_.bivae.user_encoder\n","\n","    user_mu = model_.bivae.user_mu\n","    user_ten = torch.from_numpy(user_vec)\n","    user_ten = user_ten.to(\"cuda:0\").float()\n","\n","    user_lat_vec = user_mu(user_encoder(user_ten)).view(1,-1)\n","\n","    beta_mu = model_.bivae.mu_beta\n","\n","    preds = model_.bivae.decode_user(user_lat_vec, beta_mu)\n","    preds = preds.detach().cpu().numpy().ravel()\n","    \n","    items = list(model_.iid_map.keys())\n","    all_predictions = pd.DataFrame(data = {itemcol:items})\n","    \n","\n","    all_predictions = pd.DataFrame(\n","        data={itemcol: items, predcol: preds}\n","    )\n","\n","    if remove_seen:\n","        tempdf = pd.concat(\n","            [\n","                pd.DataFrame(data = symbols, columns = [itemcol]), \n","                pd.DataFrame(\n","                    data=np.ones(len(symbols)), columns=[\"dummycol\"]\n","                ),\n","            ],\n","            axis=1,\n","        )\n","        merged = pd.merge(tempdf, all_predictions, on=[itemcol], how=\"outer\")\n","        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n","    else:\n","        return all_predictions"]},{"cell_type":"markdown","metadata":{},"source":["# score_new_user_gradio"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[],"source":["def score_new_user_gradio(\n","        symbols, \n","        model_ = model_,\n","        itemcol='itemID',\n","        predcol='pred',\n","        remove_seen=False,\n","        top_k = 10\n","        ):\n","\n","\n","    user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n","    user_vec = np.zeros(len(model_.iid_map.keys()))\n","    user_vec[user_symbol_idx] =1\n","    \n","    user_encoder = model_.bivae.user_encoder\n","\n","    user_mu = model_.bivae.user_mu\n","    user_ten = torch.from_numpy(user_vec)\n","    user_ten = user_ten.to(\"cuda:0\").float()\n","\n","    user_lat_vec = user_mu(user_encoder(user_ten)).view(1,-1)\n","\n","    beta_mu = model_.bivae.mu_beta\n","\n","    preds = model_.bivae.decode_user(user_lat_vec, beta_mu)\n","    preds = preds.detach().cpu().numpy().ravel()\n","    \n","    items = list(model_.iid_map.keys())\n","    # all_predictions = pd.DataFrame(data = {itemcol:items})\n","    \n","\n","    all_preds = pd.DataFrame(\n","        data={itemcol: items, predcol: preds}\n","    )\n","    if remove_seen:\n","        tempdf = pd.concat(\n","            [\n","                pd.DataFrame(data = symbols, columns = [itemcol]), \n","                pd.DataFrame(\n","                    data=np.ones(len(symbols)), columns=[\"dummycol\"]\n","                ),\n","            ],\n","            axis=1,\n","        )\n","        merged = pd.merge(tempdf, all_preds, on=[itemcol], how=\"outer\")\n","        all_preds = merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n","        top_k_symbols = list(all_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n","        top_k_out = '\\n'.join(top_k_symbols)\n","        return top_k_out\n","    else:\n","        top_k_symbols = list(all_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n","        top_k_out = '\\n'.join(top_k_symbols)\n","        return top_k_out\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Data processing"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"t1CgmkQ0Yn1x"},"outputs":[],"source":["def filter_dataset(dataframe, min_items, min_interactions):\n","  item_list = dataframe.groupby('itemID').filter(lambda x: len(x) >= min_items).itemID.unique().tolist()\n","  user_list = dataframe.groupby('userID').filter(lambda x: len(x) >= min_interactions).userID.unique().tolist()\n","\n","  filtered_df = dataframe[dataframe.apply(lambda row: row['itemID'] in item_list and row['userID'] in user_list, axis=1)]\n","\n","  return filtered_df"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["def read_data(file_path, min_items = 4, min_interactions = 10):\n","    df = pd.read_csv(file_path, names=[\"userID\", \"itemID\"],dtype = {'userID':np.int32}, skiprows=1)\n","    df = df.assign(rating=1)\n","    df = filter_dataset(df, min_items, min_interactions)\n","\n","    return df\n","    "]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["user_history_path = '../data/atrad_user_history_v2.csv'\n","df = pd.read_csv(user_history_path, names=[\"userID\", \"itemID\"],dtype = {'userID':np.int32}, skiprows=1)\n","df = df.assign(rating=1)\n","# df = read_data(user_history_path)"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>CIC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>LIOC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>RICH.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>WATA.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>CIC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   userID      itemID  rating\n","0       3   CIC.N0000       1\n","1       3  LIOC.N0000       1\n","2       3  RICH.N0000       1\n","3       3  WATA.N0000       1\n","4       5   CIC.N0000       1"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["def split_(stock_name):\n","    return stock_name.split('.')[0]"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[],"source":["df['itemID'] = df['itemID'].apply(lambda x : split_(x))"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"ms9UnxZDYs95"},"outputs":[],"source":["# from recommenders.datasets.python_splitters import python_random_split\n","# train_, test_ = python_stratified_split(df, 0.75)"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"7NOURFE2Qpow"},"outputs":[],"source":["# top k items to recommend\n","TOP_K = 10\n","\n","# Model parameters\n","LATENT_DIM = 70\n","USER_ENCODER_DIMS = [200,150]\n","ITEM_ENCODER_DIMS = [1000,750,250,100]\n","# ITEM_ENCODER_DIMS = [200, 100]\n","ACT_FUNC = \"relu\"\n","LIKELIHOOD = \"bern\"\n","NUM_EPOCHS = 100\n","BATCH_SIZE = 128\n","LEARNING_RATE = 0.001\n","# PLOT_LOSS = Falses\n","# CAP_PRIORS =\n","\n","bivae = BiVAECF(\n","    k=LATENT_DIM,\n","    user_encoder_structure = USER_ENCODER_DIMS,\n","    item_encoder_structure = ITEM_ENCODER_DIMS,\n","    act_fn=ACT_FUNC,\n","    likelihood=LIKELIHOOD,\n","    n_epochs=NUM_EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    learning_rate=LEARNING_RATE,\n","    # plot_loss = PLOT_LOSS,\n","    seed=69,\n","    use_gpu=torch.cuda.is_available(),\n","    verbose=True\n",")"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"snwg2lMPa8fz"},"outputs":[],"source":["# LATENT_DIM = 70\n","# USER_ENCODER_DIMS = [200, 100]\n","# ITEM_ENCODER_DIMS = [1000,750,250,100]\n","# ACT_FUNC = \"elu\"\n","# LIKELIHOOD = \"bern\"\n","# NUM_EPOCHS = 1000\n","# USER_BATCH_SIZE = 256\n","# ITEM_BATCH_SIZE = 128\n","# LEARNING_RATE = 0.001"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"Wd_J1z0vNsd-"},"outputs":[],"source":["def evaluate_recsys(model, train_set, train_, test_):\n","  model.fit(train_set);\n","  all_predictions = predict_ranking(model, train_, usercol='userID', itemcol='itemID', remove_seen=True)\n","  eval_ndcg = ndcg_at_k(test_, all_predictions, col_prediction='prediction', k=TOP_K)\n","  return eval_ndcg"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"z_36OhSqOxDo"},"outputs":[],"source":["# Split the data into four folds using stratified KFold\n","\n","def cross_val_rec_sys(df, model):\n","\n","  df = df.sample(frac=1).reset_index(drop=True)\n","\n","  NDCGs = []\n","  skf = StratifiedKFold(n_splits=4)\n","\n","  y = df['userID']\n","  X = df.drop(['userID'], axis = 1)\n","\n","  for fold, (train_indices, test_indices) in enumerate(skf.split(X,y)):\n","      train_ = df.iloc[train_indices]\n","      test_ = df.iloc[test_indices]\n","\n","      test_ = test_[test_[\"userID\"].isin(train_[\"userID\"].unique())]\n","      test_ = test_[test_[\"itemID\"].isin(train_[\"itemID\"].unique())]\n","\n","      train_set = cornac.data.Dataset.from_uir(train_.itertuples(index=False), seed= 69)\n","      test_set = cornac.data.Dataset.from_uir(test_.itertuples(index=False), seed= 69)\n","\n","      ndcg_score = evaluate_recsys(model, train_set, train_, test_)\n","      NDCGs.append(ndcg_score)\n","\n","  return statistics.mean(NDCGs), NDCGs"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"data":{"text/plain":["45819"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["df.head()\n","len(df)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate"]},{"cell_type":"code","execution_count":123,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180,"referenced_widgets":["0b40cb1420cd4226a4d74d669b2a491a","fdc131060d934fc88ea71b772d2e352f","b7fdce534a88497ab04d632d7c12b921","6e3189a12dcd48c9ad76872f89aa8bec","e9abc3821cf8411bb5e5dd501ded0d08","7114499581cd4ca791bdc7e260279451","559ce5c86e304a8a9ffda0e53cefd82e","c7ec1af5e4044dbea715a0637236f666","0617ce60f63b4dcbb1d61b184b97357a","a7528f97508848eb8249719ddd0359ea","2bfdfa5f937040a1bb202b8bbc8f70d4","e4dba2c3331c4c45bb13f88c147dfbee","6567750b878b436db71920dab561b15c","450d7076e86343d2bd2c197e03876a67","3e7f7634c59742c29e808c4e81cfab39","6920052cfbb149b7b5bf28309ac66644","3ee0a18ae6984510b3cdd684b9ffc856","062a55f970184290a6bfc11cc11777c8","102afca7f3c04b0b9fe08ea0f4525985","bd768f2ecbb4424fba1716d3a05fbc50","017703d68e3f4727b747233ec7446d55","60ecc924394349d2a110502de8812886","4e68cb9083db4308b4e823544947d00b","5ead8b0878d04fbc89b46e3f5a542ff0","f4ef613bef2e4ab9b8a42151a0193faa","e800d2347d384c30bbf425d6101256cb","ff8bfeb438f54732b55b9a35fc2f56ba","16030e4c16c84493a4e9ed394e90fa96","c2e6922c4e554c43818f9c72b117500d","1a957001934641268193ee9006a4102d","e74786af07384523a333311a8fa48cb9","5e9899046c2b48c5a054bbbdc3746b3b","8c9a828cb3f340f98c7908a0990d7747","7f4041d5d94444dfabc4bd4d6bd9e313","86dbb1ff0bf546b5ae8af0025e35695b","9c25ee51fe904c0ca948b612427fd62b","b94b8bf16d0f4445b7d17a9b708b4e50","ad7259bf3aff404987452eae14e7aeff","b56a552487454949a70bf8a8728455f1","3952f1c4578a4e8cbf9eb294af8d8d58","8092b306749d489399b853a650765886","5b297b9b83c44c3c9ed066e7c799dd28","4ce697eaa0fe42e0afba7f6b1937aec8","8607b73957824148be9465857cba4bc9"]},"executionInfo":{"elapsed":1022827,"status":"ok","timestamp":1680368549119,"user":{"displayName":"Narada Wijerathne","userId":"01570151137951130679"},"user_tz":-330},"id":"wS9sv0Q0OLTc","outputId":"307eeeb5-3afe-491c-e3f9-a68c8a43eaaa"},"outputs":[],"source":["# avg_ndcg, history = cross_val_rec_sys(df, bivae)\n","# print('avg ndcg : {}'.format(avg_ndcg))\n","# print('ndcgs : {}'.format(history))"]},{"cell_type":"markdown","metadata":{"id":"dl7xNsEQHenx"},"source":["avg ndcg : 0.3383139848729481\n","ndcgs : [0.3400926061832836, 0.3345342609929137, 0.34000738929883023, 0.338621683016765]"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["# data_uir = df.itertuples(index = False)\n","# ds = Dataset.from_uir(data_uir)"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>CIC</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>LIOC</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>RICH</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>WATA</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>CIC</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  userID itemID  rating\n","0      3    CIC       1\n","1      3   LIOC       1\n","2      3   RICH       1\n","3      3   WATA       1\n","4      5    CIC       1"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["df['userID'] = df['userID'].astype('str')\n","df.head()"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["data_uir_arr = []\n","\n","for tp in df.itertuples(index = False):\n","    data_uir_arr.append(tuple(tp))\n"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 416 duplicated observations are removed!\n","  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"]}],"source":["ds = Dataset.from_uir(data_uir_arr)"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["# data_uir_arr"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\cornac\\data\\dataset.py:335: UserWarning: 353 duplicated observations are removed!\n","  warnings.warn(\"%d duplicated observations are removed!\" % dup_count)\n"]}],"source":["test_df = df.groupby('userID').tail(1)\n","test_df_uir = test_df.itertuples(index = False)\n","test_ds = Dataset.from_uir(test_df_uir)\n","\n","train_df = df[~df.index.isin(test_df.index.to_numpy())]\n","train_df_uir = train_df.itertuples(index = False)\n","train_ds = Dataset.from_uir(train_df_uir)"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|| 100/100 [00:33<00:00,  2.98it/s, loss_i=5.38, loss_u=0.223]\n"]}],"source":["# model_ = bivae.fit(ds)"]},{"cell_type":"markdown","metadata":{},"source":["# predict_ranking()"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[],"source":["# predict_ranking_user(model_,df,'39')"]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[],"source":["# all_preds_wos = predict_ranking(model_, data = train_df, remove_seen= True)\n","# all_preds = predict_ranking(model_, data = train_df)"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[],"source":["# all_preds_wos"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[],"source":["# all_recos = predict_ranking(model_, train_ds)"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BiVAECF model is saved to ../models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl\n"]}],"source":["model_name = 'BiVAECF_alldata_{}'.format(datetime.now().strftime('%y_%m_%d_%H_%M'))\n","models_folder = '../models'\n","model_path = os.path.join(models_folder,model_name)\n","save_loc = model_.save(model_path, save_trainset=True)\n","# print(save_loc)\n"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["save_loc = r'../models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl'\n","\n","model_ = BiVAECF.load(save_loc)"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 72, 155,  67, 205, 240,  41])"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["symbols = ['SHOT','SFIN', 'LCBF', 'MAL', 'TANG', 'ASIY']\n","user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n","user_vec = np.zeros(len(model_.iid_map.keys()))\n","user_symbol_idx"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[],"source":["user_vec[user_symbol_idx] =1"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[{"data":{"text/plain":["BIL     2233\n","EXPO    2051\n","LIOC    1506\n","ACL     1383\n","LOFC    1257\n","        ... \n","SHAW       1\n","SELI       1\n","SFCL       1\n","GOOD       1\n","INDO       1\n","Name: itemID, Length: 275, dtype: int64"]},"execution_count":171,"metadata":{},"output_type":"execute_result"}],"source":["df.itemID.value_counts()"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["symbols = ['SHOT','SFIN', 'LCBF', 'MAL', 'TANG', 'ASIY']\n","\n","new_user_preds = score_new_user(\n","    symbols, \n","    model_,\n","    itemcol='itemID',\n","    predcol='pred',\n","    remove_seen=True,\n","    )"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"data":{"text/plain":["269"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["len(new_user_preds)"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"data":{"text/plain":["['BIL', 'EXPO', 'LIOC', 'ACL', 'LOFC']"]},"execution_count":165,"metadata":{},"output_type":"execute_result"}],"source":["list(new_user_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:5].values)"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[],"source":["# list(df.itemID.values)"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7863\n","\n","Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":168,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\gradio\\queueing.py\", line 495, in call_prediction\n","    output = await route_utils.call_process_api(\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\gradio\\route_utils.py\", line 231, in call_process_api\n","    output = await app.get_blocks().process_api(\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\gradio\\blocks.py\", line 1594, in process_api\n","    result = await self.call_function(\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\gradio\\blocks.py\", line 1176, in call_function\n","    prediction = await anyio.to_thread.run_sync(\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","  File \"c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\gradio\\utils.py\", line 689, in wrapper\n","    response = f(*args, **kwargs)\n","  File \"C:\\Users\\bpadmin\\AppData\\Local\\Temp\\ipykernel_18164\\521437340.py\", line 13, in score_new_user_gradio\n","    user_vec[user_symbol_idx] =1\n","IndexError: arrays used as indices must be of integer (or boolean) type\n"]}],"source":["import gradio as gr\n","\n","demo = gr.Interface(\n","    fn = score_new_user_gradio,\n","    inputs = gr.Dropdown(\n","            list(df.itemID.values),\n","             multiselect=True,\n","             label=\"symbols\",\n","             allow_custom_value = False,\n","             scale=5\n","        ),\n","    outputs = [\"text\"],\n",")\n","demo.launch(share = True)\n","\n","# businesses in the domain of shipping and logistics"]},{"cell_type":"markdown","metadata":{},"source":["# Sandbox"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["user_history_path = '../data/atrad_user_history_v2.csv'\n","df = pd.read_csv(user_history_path, names=[\"userID\", \"itemID\"],dtype = {'userID':np.int32}, skiprows=1)\n","df = df.assign(rating=1)\n","# df = read_data(user_history_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(289, 1494)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["item_list = df.groupby('itemID').filter(lambda x: len(x) >= 4).itemID.unique().tolist()\n","user_list = df.groupby('userID').filter(lambda x: len(x) >= 10).userID.unique().tolist()\n","\n","len(item_list), len(user_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def item_check_(item, df, occ = 4):\n","    item_list = df.groupby('itemID').filter(lambda x: len(x) >= occ).itemID.unique().tolist()\n","    if item in item_list:\n","        return True\n","    else:\n","        return False\n","    \n","def user_check_(user, df, occ = 4):\n","    item_list = df.groupby('userID').filter(lambda x: len(x) >= occ).itemID.unique().tolist()\n","    if user in user_list:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>LIOC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>RICH.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>WATA.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>CIC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>LIOC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>45814</th>\n","      <td>69342</td>\n","      <td>LIOC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45815</th>\n","      <td>69342</td>\n","      <td>LOLC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45816</th>\n","      <td>69342</td>\n","      <td>MELS.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45817</th>\n","      <td>99999</td>\n","      <td>EXPO.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45818</th>\n","      <td>99999</td>\n","      <td>LIOC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>45818 rows  3 columns</p>\n","</div>"],"text/plain":["       userID      itemID  rating\n","1           3  LIOC.N0000       1\n","2           3  RICH.N0000       1\n","3           3  WATA.N0000       1\n","4           5   CIC.N0000       1\n","5           5  LIOC.N0000       1\n","...       ...         ...     ...\n","45814   69342  LIOC.N0000       1\n","45815   69342  LOLC.N0000       1\n","45816   69342  MELS.N0000       1\n","45817   99999  EXPO.N0000       1\n","45818   99999  LIOC.N0000       1\n","\n","[45818 rows x 3 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["df.iloc[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def item_filter(df, mask_list):\n","    for k, row in df.iterrows():\n","        item_bool = item_check_(row['itemID'], df)\n","        user_bool = user_check_(row['userID'], df)\n","\n","        fil_mask = item_bool & user_bool\n","        mask_list.append(fil_mask)\n","        \n","        df = df.iloc[k:]\n","        item_filter(df,mask_list)\n","\n","        return mask_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mask_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m filter_mask \u001b[38;5;241m=\u001b[39m \u001b[43mitem_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[42], line 10\u001b[0m, in \u001b[0;36mitem_filter\u001b[1;34m(df, mask_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m mask_list\u001b[38;5;241m.\u001b[39mappend(fil_mask)\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[k:]\n\u001b[1;32m---> 10\u001b[0m \u001b[43mitem_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask_list\n","Cell \u001b[1;32mIn[42], line 10\u001b[0m, in \u001b[0;36mitem_filter\u001b[1;34m(df, mask_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m mask_list\u001b[38;5;241m.\u001b[39mappend(fil_mask)\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[k:]\n\u001b[1;32m---> 10\u001b[0m \u001b[43mitem_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask_list\n","    \u001b[1;31m[... skipping similar frames: item_filter at line 10 (1825 times)]\u001b[0m\n","Cell \u001b[1;32mIn[42], line 10\u001b[0m, in \u001b[0;36mitem_filter\u001b[1;34m(df, mask_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m mask_list\u001b[38;5;241m.\u001b[39mappend(fil_mask)\n\u001b[0;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[k:]\n\u001b[1;32m---> 10\u001b[0m \u001b[43mitem_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask_list\n","Cell \u001b[1;32mIn[42], line 4\u001b[0m, in \u001b[0;36mitem_filter\u001b[1;34m(df, mask_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      3\u001b[0m     item_bool \u001b[38;5;241m=\u001b[39m item_check_(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitemID\u001b[39m\u001b[38;5;124m'\u001b[39m], df)\n\u001b[1;32m----> 4\u001b[0m     user_bool \u001b[38;5;241m=\u001b[39m \u001b[43muser_check_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     fil_mask \u001b[38;5;241m=\u001b[39m item_bool \u001b[38;5;241m&\u001b[39m user_bool\n\u001b[0;32m      7\u001b[0m     mask_list\u001b[38;5;241m.\u001b[39mappend(fil_mask)\n","Cell \u001b[1;32mIn[40], line 9\u001b[0m, in \u001b[0;36muser_check_\u001b[1;34m(user, df, occ)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_check_\u001b[39m(user, df, occ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     item_list \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mocc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitemID\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m user_list:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1379\u001b[0m, in \u001b[0;36mDataFrameGroupBy.filter\u001b[1;34m(self, func, dropna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1376\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\n\u001b[0;32m   1377\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mget_iterator(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis)\n\u001b[1;32m-> 1379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[0;32m   1382\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:788\u001b[0m, in \u001b[0;36mBaseGrouper.get_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_iterator\u001b[39m(\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28mself\u001b[39m, data: NDFrameT, axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    779\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mtuple\u001b[39m[Hashable, NDFrameT]]:\n\u001b[0;32m    780\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;124;03m    Groupby iterator\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;124;03m    for each group\u001b[39;00m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_keys_seq\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:799\u001b[0m, in \u001b[0;36mBaseGrouper._get_splitter\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_splitter\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: NDFrame, axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataSplitter:\n\u001b[0;32m    794\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;124;03m    Generator yielding subsetted objects\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m     ids, _, ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_splitter(data, ids, ngroups, axis\u001b[38;5;241m=\u001b[39maxis)\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:946\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m--> 946\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[0;32m    949\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:977\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n\u001b[0;32m    976\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39mgroup_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:621\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;66;03m# _codes is set in __init__ for MultiIndex cases\u001b[39;00m\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\_libs\\properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:692\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    686\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouping_vector\u001b[38;5;241m.\u001b[39mresult_index\u001b[38;5;241m.\u001b[39m_values  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     )\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\algorithms.py:822\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    820\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 822\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m na_sentinel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;66;03m# TODO: Can remove when na_sentinel=na_sentinel as in TODO above\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\pandas\\core\\algorithms.py:578\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    575\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    577\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 578\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    587\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["mask_list = []\n","\n","filter_mask = item_filter(df, mask_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filter_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19</th>\n","      <td>39</td>\n","      <td>TILE.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>44</td>\n","      <td>SUN.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>116</td>\n","      <td>PABC.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>146</td>\n","      <td>UAL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>190</td>\n","      <td>TKYO.N0000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    userID      itemID  rating\n","19      39  TILE.N0000       1\n","29      44   SUN.N0000       1\n","52     116  PABC.N0000       1\n","66     146   UAL.N0000       1\n","103    190  TKYO.N0000       1"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_unq_items = list(test_df.itemID.unique())\n","train_unq_items = list(train_df.itemID.unique())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["set(test_unq_items).issubset(set(train_unq_items))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["YORK.N0000\n"]}],"source":["for item in test_unq_items:\n","    if item not in train_unq_items:\n","        print(item)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["UDPL.N0000    32\n","UBC.N0000     31\n","SCAP.N0000    28\n","RCL.N0000     28\n","TESS.N0000    28\n","TKYO.N0000    23\n","TJL.N0000     23\n","SLTL.N0000    20\n","YORK.N0000    19\n","TPL.N0000     16\n","Name: itemID, dtype: int64"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["test_df.itemID.value_counts()[10:20] #.loc['YORK.N0000']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["BIL.N0000     947\n","EXPO.N0000    917\n","LIOC.N0000    794\n","ACL.N0000     767\n","LOFC.N0000    646\n","             ... \n","HARI.N0000      2\n","KDL.N0000       2\n","CTHR.N0000      2\n","CIT.N0000       2\n","WIND.N0000      1\n","Name: itemID, Length: 290, dtype: int64"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["train_df.itemID.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>39</td>\n","      <td>ACL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>39</td>\n","      <td>BIL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>39</td>\n","      <td>BRWN.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>39</td>\n","      <td>DIPD.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>39</td>\n","      <td>EXPO.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>45804</th>\n","      <td>69334</td>\n","      <td>MELS.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45805</th>\n","      <td>69334</td>\n","      <td>RCL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45806</th>\n","      <td>69334</td>\n","      <td>SAMP.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45807</th>\n","      <td>69334</td>\n","      <td>SUN.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>45808</th>\n","      <td>69334</td>\n","      <td>VONE.N0000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29376 rows  3 columns</p>\n","</div>"],"text/plain":["      userID      itemID  rating\n","10        39   ACL.N0000       1\n","11        39   BIL.N0000       1\n","12        39  BRWN.N0000       1\n","13        39  DIPD.N0000       1\n","14        39  EXPO.N0000       1\n","...      ...         ...     ...\n","45804  69334  MELS.N0000       1\n","45805  69334   RCL.N0000       1\n","45806  69334  SAMP.N0000       1\n","45807  69334   SUN.N0000       1\n","45808  69334  VONE.N0000       1\n","\n","[29376 rows x 3 columns]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from recommenders.datasets.python_splitters import numpy_stratified_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([['39', 'ACL.N0000'],\n","       ['39', 'BIL.N0000'],\n","       ['39', 'BRWN.N0000'],\n","       ...,\n","       ['69334', 'SUN.N0000'],\n","       ['69334', 'VONE.N0000'],\n","       ['69334', 'WATA.N0000']], dtype=object)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["X = df[['userID','itemID']].to_numpy()\n","X"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_arr, test_arr = numpy_stratified_split(X, ratio = 0.75, seed = 69)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([['39', 'ACL.N0000'],\n","       ['39', 'BIL.N0000'],\n","       ['39', 'BRWN.N0000'],\n","       ...,\n","       ['69334', 'SUN.N0000'],\n","       ['69334', 'VONE.N0000'],\n","       ['69334', 'WATA.N0000']], dtype=object)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["train_arr"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>itemID</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10</th>\n","      <td>39</td>\n","      <td>ACL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>39</td>\n","      <td>BIL.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>39</td>\n","      <td>BRWN.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>39</td>\n","      <td>DIPD.N0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>39</td>\n","      <td>EXPO.N0000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   userID      itemID  rating\n","10     39   ACL.N0000       1\n","11     39   BIL.N0000       1\n","12     39  BRWN.N0000       1\n","13     39  DIPD.N0000       1\n","14     39  EXPO.N0000       1"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["train_arr.shape, test_arr.shape\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from recommenders.datasets.python_splitters import python_stratified_split\n","\n","[tr_df, ts_df] = python_stratified_split(data = df, ratio = 0.75, filter_by='item')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(1494, 291)"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["df.userID.nunique(), df.itemID.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["HARI.N0000      2\n","CTHR.N0000      2\n","CIT.N0000       2\n","KDL.N0000       2\n","UCAR.N0000      3\n","             ... \n","RCL.N0000     651\n","ACL.N0000     767\n","LIOC.N0000    795\n","EXPO.N0000    917\n","BIL.N0000     947\n","Name: itemID, Length: 291, dtype: int64"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["df.itemID.value_counts().sort_values()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(1494, 291)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["tr_df.userID.nunique(), tr_df.itemID.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(1449, 287)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["ts_df.userID.nunique(), ts_df.itemID.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNThV6Ewp1Gk9kULVBlVl+6","provenance":[{"file_id":"1nrt12w-UoVAXRKrx63q3Fd7XqSN5QWz8","timestamp":1705914302854}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"017703d68e3f4727b747233ec7446d55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0617ce60f63b4dcbb1d61b184b97357a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"062a55f970184290a6bfc11cc11777c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b40cb1420cd4226a4d74d669b2a491a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdc131060d934fc88ea71b772d2e352f","IPY_MODEL_b7fdce534a88497ab04d632d7c12b921","IPY_MODEL_6e3189a12dcd48c9ad76872f89aa8bec"],"layout":"IPY_MODEL_e9abc3821cf8411bb5e5dd501ded0d08"}},"102afca7f3c04b0b9fe08ea0f4525985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16030e4c16c84493a4e9ed394e90fa96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a957001934641268193ee9006a4102d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bfdfa5f937040a1bb202b8bbc8f70d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3952f1c4578a4e8cbf9eb294af8d8d58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e7f7634c59742c29e808c4e81cfab39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_017703d68e3f4727b747233ec7446d55","placeholder":"","style":"IPY_MODEL_60ecc924394349d2a110502de8812886","value":" 1000/1000 [04:13&lt;00:00,  3.67it/s, loss_i=1.66, loss_u=0.217]"}},"3ee0a18ae6984510b3cdd684b9ffc856":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450d7076e86343d2bd2c197e03876a67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_102afca7f3c04b0b9fe08ea0f4525985","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd768f2ecbb4424fba1716d3a05fbc50","value":1000}},"4ce697eaa0fe42e0afba7f6b1937aec8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e68cb9083db4308b4e823544947d00b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ead8b0878d04fbc89b46e3f5a542ff0","IPY_MODEL_f4ef613bef2e4ab9b8a42151a0193faa","IPY_MODEL_e800d2347d384c30bbf425d6101256cb"],"layout":"IPY_MODEL_ff8bfeb438f54732b55b9a35fc2f56ba"}},"559ce5c86e304a8a9ffda0e53cefd82e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b297b9b83c44c3c9ed066e7c799dd28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e9899046c2b48c5a054bbbdc3746b3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ead8b0878d04fbc89b46e3f5a542ff0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16030e4c16c84493a4e9ed394e90fa96","placeholder":"","style":"IPY_MODEL_c2e6922c4e554c43818f9c72b117500d","value":"100%"}},"60ecc924394349d2a110502de8812886":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6567750b878b436db71920dab561b15c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee0a18ae6984510b3cdd684b9ffc856","placeholder":"","style":"IPY_MODEL_062a55f970184290a6bfc11cc11777c8","value":"100%"}},"6920052cfbb149b7b5bf28309ac66644":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e3189a12dcd48c9ad76872f89aa8bec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7528f97508848eb8249719ddd0359ea","placeholder":"","style":"IPY_MODEL_2bfdfa5f937040a1bb202b8bbc8f70d4","value":" 1000/1000 [04:16&lt;00:00,  3.00it/s, loss_i=1.66, loss_u=0.217]"}},"7114499581cd4ca791bdc7e260279451":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f4041d5d94444dfabc4bd4d6bd9e313":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86dbb1ff0bf546b5ae8af0025e35695b","IPY_MODEL_9c25ee51fe904c0ca948b612427fd62b","IPY_MODEL_b94b8bf16d0f4445b7d17a9b708b4e50"],"layout":"IPY_MODEL_ad7259bf3aff404987452eae14e7aeff"}},"8092b306749d489399b853a650765886":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8607b73957824148be9465857cba4bc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86dbb1ff0bf546b5ae8af0025e35695b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b56a552487454949a70bf8a8728455f1","placeholder":"","style":"IPY_MODEL_3952f1c4578a4e8cbf9eb294af8d8d58","value":"100%"}},"8c9a828cb3f340f98c7908a0990d7747":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c25ee51fe904c0ca948b612427fd62b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8092b306749d489399b853a650765886","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b297b9b83c44c3c9ed066e7c799dd28","value":1000}},"a7528f97508848eb8249719ddd0359ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7259bf3aff404987452eae14e7aeff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b56a552487454949a70bf8a8728455f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7fdce534a88497ab04d632d7c12b921":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ec1af5e4044dbea715a0637236f666","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0617ce60f63b4dcbb1d61b184b97357a","value":1000}},"b94b8bf16d0f4445b7d17a9b708b4e50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ce697eaa0fe42e0afba7f6b1937aec8","placeholder":"","style":"IPY_MODEL_8607b73957824148be9465857cba4bc9","value":" 1000/1000 [04:14&lt;00:00,  4.17it/s, loss_i=1.64, loss_u=0.218]"}},"bd768f2ecbb4424fba1716d3a05fbc50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2e6922c4e554c43818f9c72b117500d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7ec1af5e4044dbea715a0637236f666":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4dba2c3331c4c45bb13f88c147dfbee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6567750b878b436db71920dab561b15c","IPY_MODEL_450d7076e86343d2bd2c197e03876a67","IPY_MODEL_3e7f7634c59742c29e808c4e81cfab39"],"layout":"IPY_MODEL_6920052cfbb149b7b5bf28309ac66644"}},"e74786af07384523a333311a8fa48cb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e800d2347d384c30bbf425d6101256cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e9899046c2b48c5a054bbbdc3746b3b","placeholder":"","style":"IPY_MODEL_8c9a828cb3f340f98c7908a0990d7747","value":" 1000/1000 [04:13&lt;00:00,  4.14it/s, loss_i=1.67, loss_u=0.217]"}},"e9abc3821cf8411bb5e5dd501ded0d08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4ef613bef2e4ab9b8a42151a0193faa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a957001934641268193ee9006a4102d","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e74786af07384523a333311a8fa48cb9","value":1000}},"fdc131060d934fc88ea71b772d2e352f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7114499581cd4ca791bdc7e260279451","placeholder":"","style":"IPY_MODEL_559ce5c86e304a8a9ffda0e53cefd82e","value":"100%"}},"ff8bfeb438f54732b55b9a35fc2f56ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
