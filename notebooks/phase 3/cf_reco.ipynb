{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io \n",
    "import sys\n",
    "from PIL import Image\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from cornac.models.recommender import Recommender\n",
    "from cornac.utils.common import scale\n",
    "from cornac.exception import ScoreException\n",
    "\n",
    "from cornac.models.recommender import ANNMixin, MEASURE_DOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiVAECF(Recommender):\n",
    "    \"\"\"Bilateral Variational AutoEncoder for Collaborative Filtering.\n",
    "    Parameters\n",
    "    ----------\n",
    "    k: int, optional, default: 10\n",
    "        The dimension of the stochastic user ``theta'' and item ``beta'' factors.\n",
    "    encoder_structure: list, default: [20]\n",
    "        The number of neurons per layer of the user and item encoders for BiVAE.\n",
    "        For example, encoder_structure = [20], the user (item) encoder structure will be [num_items, 20, k] ([num_users, 20, k]).\n",
    "    act_fn: str, default: 'tanh'\n",
    "        Name of the activation function used between hidden layers of the auto-encoder.\n",
    "        Supported functions: ['sigmoid', 'tanh', 'elu', 'relu', 'relu6']\n",
    "    likelihood: str, default: 'pois'\n",
    "        The likelihood function used for modeling the observations.\n",
    "        Supported choices:\n",
    "        bern: Bernoulli likelihood\n",
    "        gaus: Gaussian likelihood\n",
    "        pois: Poisson likelihood\n",
    "    n_epochs: int, optional, default: 100\n",
    "        The number of epochs for SGD.\n",
    "    batch_size: int, optional, default: 100\n",
    "        The batch size.\n",
    "    learning_rate: float, optional, default: 0.001\n",
    "        The learning rate for Adam.\n",
    "    beta_kl: float, optional, default: 1.0\n",
    "        The weight of the KL terms as in beta-VAE.\n",
    "    cap_priors: dict, optional, default: {\"user\":False, \"item\":False}\n",
    "        When {\"user\":True, \"item\":True}, CAP priors are used (see BiVAE paper for details),\\\n",
    "        otherwise the standard Normal is used as a Prior over the user and item latent variables.\n",
    "    name: string, optional, default: 'BiVAECF'\n",
    "        The name of the recommender model.\n",
    "    trainable: boolean, optional, default: True\n",
    "        When False, the model is not trained and Cornac assumes that the model is already \\\n",
    "        pre-trained.\n",
    "    verbose: boolean, optional, default: False\n",
    "        When True, some running logs are displayed.\n",
    "    seed: int, optional, default: None\n",
    "        Random seed for parameters initialization.\n",
    "    use_gpu: boolean, optional, default: True\n",
    "        If True and your system supports CUDA then training is performed on GPUs.\n",
    "    References\n",
    "    ----------\n",
    "    * Quoc-Tuan Truong, Aghiles Salah, Hady W. Lauw. \" Bilateral Variational Autoencoder for Collaborative Filtering.\"\n",
    "    ACM International Conference on Web Search and Data Mining (WSDM). 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=\"BiVAECF\",\n",
    "        k=10,\n",
    "        user_encoder_structure=[20],\n",
    "        item_encoder_structure = [20],\n",
    "        act_fn=\"tanh\",\n",
    "        likelihood=\"pois\",\n",
    "        n_epochs=100,\n",
    "        user_batch_size=100,\n",
    "        item_batch_size = 100,\n",
    "        user_learning_rate=0.001,\n",
    "        item_learning_rate=0.001,\n",
    "        beta_kl=1.0,\n",
    "        cap_priors={\"user\": False, \"item\": False},\n",
    "        trainable=True,\n",
    "        verbose=False,\n",
    "        seed=None,\n",
    "        use_gpu=True,\n",
    "        plot_loss = False,\n",
    "    ):\n",
    "        Recommender.__init__(self, name=name, trainable=trainable, verbose=verbose)\n",
    "        self.k = k\n",
    "        self.user_encoder_structure = user_encoder_structure\n",
    "        self.item_encoder_structure = item_encoder_structure\n",
    "        self.act_fn = act_fn\n",
    "        self.likelihood = likelihood\n",
    "        self.user_batch_size = user_batch_size\n",
    "        self.item_batch_size = item_batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.user_learning_rate = user_learning_rate\n",
    "        self.item_learning_rate = item_learning_rate\n",
    "        self.beta_kl = beta_kl\n",
    "        self.cap_priors = cap_priors\n",
    "        self.seed = seed\n",
    "        self.use_gpu = use_gpu\n",
    "        self.plot_loss = plot_loss\n",
    "\n",
    "    def fit(self, train_set, val_set=None):\n",
    "        \"\"\"Fit the model to observations.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_set: :obj:`cornac.data.Dataset`, required\n",
    "            User-Item preference data as well as additional modalities.\n",
    "        val_set: :obj:`cornac.data.Dataset`, optional, default: None\n",
    "            User-Item preference data for model selection purposes (e.g., early stopping).\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        Recommender.fit(self, train_set, val_set)\n",
    "\n",
    "        self.device = (\n",
    "            torch.device(\"cuda:0\")\n",
    "            if (self.use_gpu and torch.cuda.is_available())\n",
    "            else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "        if self.trainable:\n",
    "            feature_dim = {\"user\": None, \"item\": None}\n",
    "            if self.cap_priors.get(\"user\", False):\n",
    "                if train_set.user_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for users is set to True but no user features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"user\"] = train_set.user_feature.feature_dim\n",
    "\n",
    "            if self.cap_priors.get(\"item\", False):\n",
    "                if train_set.item_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for items is set to True but no item features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"item\"] = train_set.item_feature.feature_dim\n",
    "\n",
    "            if self.seed is not None:\n",
    "                torch.manual_seed(self.seed)\n",
    "                torch.cuda.manual_seed(self.seed)\n",
    "\n",
    "            if not hasattr(self, \"bivaecf\"):\n",
    "                num_items = train_set.matrix.shape[1]\n",
    "                num_users = train_set.matrix.shape[0]\n",
    "                self.bivae = BiVAE(\n",
    "                    k=self.k,\n",
    "                    #changes\n",
    "                    user_encoder_structure=[num_items] + self.user_encoder_structure,\n",
    "                    item_encoder_structure=[num_users] + self.item_encoder_structure,\n",
    "                    #changes end\n",
    "                    act_fn=self.act_fn,\n",
    "                    likelihood=self.likelihood,\n",
    "                    cap_priors=self.cap_priors,\n",
    "                    feature_dim=feature_dim,\n",
    "                    user_batch_size=self.user_batch_size,\n",
    "                    item_batch_size = self.item_batch_size\n",
    "                ).to(self.device)\n",
    "\n",
    "            learn(\n",
    "                self.bivae,\n",
    "                self.train_set,\n",
    "                n_epochs=self.n_epochs,\n",
    "                user_batch_size=self.user_batch_size,\n",
    "                item_batch_size = self.user_batch_size,\n",
    "                user_learn_rate=self.user_learning_rate,\n",
    "                item_learn_rate = self.item_learning_rate,\n",
    "                beta_kl=self.beta_kl,\n",
    "                verbose=self.verbose,\n",
    "                device=self.device,\n",
    "                plot_loss = self.plot_loss,\n",
    "            )\n",
    "\n",
    "        elif self.verbose:\n",
    "            print(\"%s is trained already (trainable = False)\" % (self.name))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def score(self, user_idx, item_idx=None):\n",
    "        \"\"\"Predict the scores/ratings of a user for an item.\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_idx: int, required\n",
    "            The index of the user for whom to perform score prediction.\n",
    "        item_idx: int, optional, default: None\n",
    "            The index of the item for which to perform score prediction.\n",
    "            If None, scores for all known items will be returned.\n",
    "        Returns\n",
    "        -------\n",
    "        res : A scalar or a Numpy array\n",
    "            Relative scores that the user gives to the item or to all known items\n",
    "        \"\"\"\n",
    "\n",
    "        if item_idx is None:\n",
    "            if self.train_set.is_unk_user(user_idx):\n",
    "                raise ScoreException(\n",
    "                    \"Can't make score prediction for (user_id=%d)\" % user_idx\n",
    "                )\n",
    "\n",
    "            theta_mu_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            # theta_u = self.bivae.theta[user_idx].view(1, -1)\n",
    "            beta = self.bivae.mu_beta\n",
    "            known_item_scores = (\n",
    "                self.bivae.decode_user(theta_mu_u, beta).cpu().numpy().ravel()\n",
    "                # self.bivae.decode_user(theta, beta).cpu().detach().numpy().ravel()\n",
    "            )\n",
    "\n",
    "            return known_item_scores\n",
    "        else:\n",
    "            if self.train_set.is_unk_user(user_idx) or self.train_set.is_unk_item(\n",
    "                item_idx\n",
    "            ):\n",
    "                raise ScoreException(\n",
    "                    \"Can't make score prediction for (user_id=%d, item_id=%d)\"\n",
    "                    % (user_idx, item_idx)\n",
    "                )\n",
    "\n",
    "            theta_mu_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            # theta_u = self.bivae.theta[user_idx].view(1, -1)\n",
    "            beta_i = self.bivae.mu_beta[item_idx].view(1, -1)\n",
    "            pred = self.bivae.decode_user(theta_mu_u, beta_i).cpu().numpy().ravel()\n",
    "            # pred = self.bivae.decode_user(theta_u, beta).cpu().detach().numpy().ravel()\n",
    "\n",
    "            pred = scale(\n",
    "                pred, self.train_set.min_rating, self.train_set.max_rating, 0.0, 1.0\n",
    "            )\n",
    "\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cornac 1.18 BiVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bivae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 The Cornac Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import trange\n",
    "\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "ACT = {\n",
    "    \"sigmoid\": nn.Sigmoid(),\n",
    "    \"tanh\": nn.Tanh(),\n",
    "    \"elu\": nn.ELU(),\n",
    "    \"relu\": nn.ReLU(),\n",
    "    \"relu6\": nn.ReLU6(),\n",
    "}\n",
    "\n",
    "\n",
    "class BiVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k,\n",
    "        user_encoder_structure,\n",
    "        item_encoder_structure,\n",
    "        act_fn,\n",
    "        likelihood,\n",
    "        cap_priors,\n",
    "        feature_dim,\n",
    "        batch_size,\n",
    "    ):\n",
    "        super(BiVAE, self).__init__()\n",
    "\n",
    "        self.mu_theta = torch.zeros((item_encoder_structure[0], k))  # n_users*k\n",
    "        self.mu_beta = torch.zeros((user_encoder_structure[0], k))  # n_items*k\n",
    "\n",
    "        self.theta = torch.randn(item_encoder_structure[0], k) * 0.01\n",
    "        self.beta = torch.randn(user_encoder_structure[0], k) * 0.01\n",
    "        torch.nn.init.kaiming_uniform_(self.theta, a=np.sqrt(5))\n",
    "\n",
    "        self.likelihood = likelihood\n",
    "        self.act_fn = ACT.get(act_fn, None)\n",
    "        if self.act_fn is None:\n",
    "            raise ValueError(\"Supported act_fn: {}\".format(ACT.keys()))\n",
    "\n",
    "        self.cap_priors = cap_priors\n",
    "        if self.cap_priors.get(\"user\", False):\n",
    "            self.user_prior_encoder = nn.Linear(feature_dim.get(\"user\"), k)\n",
    "        if self.cap_priors.get(\"item\", False):\n",
    "            self.item_prior_encoder = nn.Linear(feature_dim.get(\"item\"), k)\n",
    "\n",
    "        # User Encoder\n",
    "        self.user_encoder = nn.Sequential()\n",
    "        for i in range(len(user_encoder_structure) - 1):\n",
    "            self.user_encoder.add_module(\n",
    "                \"fc{}\".format(i),\n",
    "                nn.Linear(user_encoder_structure[i], user_encoder_structure[i + 1]),\n",
    "            )\n",
    "            self.user_encoder.add_module(\"act{}\".format(i), self.act_fn)\n",
    "        self.user_mu = nn.Linear(user_encoder_structure[-1], k)  # mu\n",
    "        self.user_std = nn.Linear(user_encoder_structure[-1], k)\n",
    "\n",
    "        # Item Encoder\n",
    "        self.item_encoder = nn.Sequential()\n",
    "        for i in range(len(item_encoder_structure) - 1):\n",
    "            self.item_encoder.add_module(\n",
    "                \"fc{}\".format(i),\n",
    "                nn.Linear(item_encoder_structure[i], item_encoder_structure[i + 1]),\n",
    "            )\n",
    "            self.item_encoder.add_module(\"act{}\".format(i), self.act_fn)\n",
    "        self.item_mu = nn.Linear(item_encoder_structure[-1], k)  # mu\n",
    "        self.item_std = nn.Linear(item_encoder_structure[-1], k)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.beta = self.beta.to(device=device)\n",
    "        self.theta = self.theta.to(device=device)\n",
    "        self.mu_beta = self.mu_beta.to(device=device)\n",
    "        self.mu_theta = self.mu_theta.to(device=device)\n",
    "        return super(BiVAE, self).to(device)\n",
    "\n",
    "    def encode_user_prior(self, x):\n",
    "        h = self.user_prior_encoder(x)\n",
    "        return h\n",
    "\n",
    "    def encode_item_prior(self, x):\n",
    "        h = self.item_prior_encoder(x)\n",
    "        return h\n",
    "\n",
    "    def encode_user(self, x):\n",
    "        h = self.user_encoder(x)\n",
    "        return self.user_mu(h), torch.sigmoid(self.user_std(h))\n",
    "\n",
    "    def encode_item(self, x):\n",
    "        h = self.item_encoder(x)\n",
    "        return self.item_mu(h), torch.sigmoid(self.item_std(h))\n",
    "\n",
    "    def decode_user(self, theta, beta):\n",
    "        h = theta.mm(beta.t())\n",
    "        return torch.sigmoid(h)\n",
    "\n",
    "    def decode_item(self, theta, beta):\n",
    "        h = beta.mm(theta.t())\n",
    "        return torch.sigmoid(h)\n",
    "\n",
    "    def reparameterize(self, mu, std):\n",
    "        eps = torch.randn_like(mu)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, user=True, beta=None, theta=None):\n",
    "\n",
    "        if user:\n",
    "            mu, std = self.encode_user(x)\n",
    "            theta = self.reparameterize(mu, std)\n",
    "            return theta, self.decode_user(theta, beta), mu, std\n",
    "        else:\n",
    "            mu, std = self.encode_item(x)\n",
    "            beta = self.reparameterize(mu, std)\n",
    "            return beta, self.decode_item(theta, beta), mu, std\n",
    "\n",
    "    def loss(self, x, x_, mu, mu_prior, std, kl_beta):\n",
    "        # Likelihood\n",
    "        ll_choices = {\n",
    "            \"bern\": x * torch.log(x_ + EPS) + (1 - x) * torch.log(1 - x_ + EPS),\n",
    "            \"gaus\": -(x - x_) ** 2,\n",
    "            \"pois\": x * torch.log(x_ + EPS) - x_,\n",
    "        }\n",
    "\n",
    "        ll = ll_choices.get(self.likelihood, None)\n",
    "        if ll is None:\n",
    "            raise ValueError(\"Supported likelihoods: {}\".format(ll_choices.keys()))\n",
    "\n",
    "        ll = torch.sum(ll, dim=1)\n",
    "\n",
    "        # KL term\n",
    "        kld = -0.5 * (1 + 2.0 * torch.log(std) - (mu - mu_prior).pow(2) - std.pow(2))\n",
    "        kld = torch.sum(kld, dim=1)\n",
    "\n",
    "        return torch.mean(kl_beta * kld - ll)\n",
    "\n",
    "\n",
    "def learn(\n",
    "    bivae,\n",
    "    train_set,\n",
    "    n_epochs,\n",
    "    batch_size,\n",
    "    learn_rate,\n",
    "    beta_kl,\n",
    "    verbose,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    dtype=torch.float32,\n",
    "):\n",
    "    user_params = it.chain(\n",
    "        bivae.user_encoder.parameters(),\n",
    "        bivae.user_mu.parameters(),\n",
    "        bivae.user_std.parameters(),\n",
    "    )\n",
    "\n",
    "    item_params = it.chain(\n",
    "        bivae.item_encoder.parameters(),\n",
    "        bivae.item_mu.parameters(),\n",
    "        bivae.item_std.parameters(),\n",
    "    )\n",
    "\n",
    "    if bivae.cap_priors.get(\"user\", False):\n",
    "        user_params = it.chain(user_params, bivae.user_prior_encoder.parameters())\n",
    "        user_features = train_set.user_feature.features[: train_set.num_users]\n",
    "\n",
    "    if bivae.cap_priors.get(\"item\", False):\n",
    "        item_params = it.chain(item_params, bivae.item_prior_encoder.parameters())\n",
    "        item_features = train_set.item_feature.features[: train_set.num_items]\n",
    "\n",
    "    u_optimizer = torch.optim.Adam(params=user_params, lr=learn_rate)\n",
    "    i_optimizer = torch.optim.Adam(params=item_params, lr=learn_rate)\n",
    "\n",
    "    x = train_set.matrix.copy()\n",
    "    x.data = np.ones_like(x.data)  # Binarize data\n",
    "    tx = x.transpose()\n",
    "\n",
    "    progress_bar = trange(1, n_epochs + 1, disable=not verbose)\n",
    "    for _ in progress_bar:\n",
    "        # item side\n",
    "        i_sum_loss = 0.0\n",
    "        i_count = 0\n",
    "        for i_ids in train_set.item_iter(batch_size, shuffle=False):\n",
    "            i_batch = tx[i_ids, :]\n",
    "            i_batch = i_batch.A\n",
    "            i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n",
    "\n",
    "            # Reconstructed batch\n",
    "            beta, i_batch_, i_mu, i_std = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "\n",
    "            i_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n",
    "            if bivae.cap_priors.get(\"item\", False):\n",
    "                i_batch_f = item_features[i_ids]\n",
    "                i_batch_f = torch.tensor(i_batch_f, dtype=dtype, device=device)\n",
    "                i_mu_prior = bivae.encode_item_prior(i_batch_f)\n",
    "\n",
    "            i_loss = bivae.loss(i_batch, i_batch_, i_mu, i_mu_prior, i_std, beta_kl)\n",
    "            i_optimizer.zero_grad()\n",
    "            i_loss.backward()\n",
    "            i_optimizer.step()\n",
    "\n",
    "            i_sum_loss += i_loss.data.item()\n",
    "            i_count += len(i_batch)\n",
    "\n",
    "            beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "\n",
    "            bivae.beta.data[i_ids] = beta.data\n",
    "            bivae.mu_beta.data[i_ids] = i_mu.data\n",
    "\n",
    "        # user side\n",
    "        u_sum_loss = 0.0\n",
    "        u_count = 0\n",
    "        for u_ids in train_set.user_iter(batch_size, shuffle=False):\n",
    "            u_batch = x[u_ids, :]\n",
    "            u_batch = u_batch.A\n",
    "            u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n",
    "\n",
    "            # Reconstructed batch\n",
    "            theta, u_batch_, u_mu, u_std = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "\n",
    "            u_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n",
    "            if bivae.cap_priors.get(\"user\", False):\n",
    "                u_batch_f = user_features[u_ids]\n",
    "                u_batch_f = torch.tensor(u_batch_f, dtype=dtype, device=device)\n",
    "                u_mu_prior = bivae.encode_user_prior(u_batch_f)\n",
    "\n",
    "            u_loss = bivae.loss(u_batch, u_batch_, u_mu, u_mu_prior, u_std, beta_kl)\n",
    "            u_optimizer.zero_grad()\n",
    "            u_loss.backward()\n",
    "            u_optimizer.step()\n",
    "\n",
    "            u_sum_loss += u_loss.data.item()\n",
    "            u_count += len(u_batch)\n",
    "\n",
    "            theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "            bivae.theta.data[u_ids] = theta.data\n",
    "            bivae.mu_theta.data[u_ids] = u_mu.data\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss_i=(i_sum_loss / i_count), loss_u=(u_sum_loss / (u_count))\n",
    "            )\n",
    "\n",
    "    # infer mu_beta\n",
    "    for i_ids in train_set.item_iter(batch_size, shuffle=False):\n",
    "        i_batch = tx[i_ids, :]\n",
    "        i_batch = i_batch.A\n",
    "        i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n",
    "\n",
    "        beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "        bivae.mu_beta.data[i_ids] = i_mu.data\n",
    "\n",
    "    # infer mu_theta\n",
    "    for u_ids in train_set.user_iter(batch_size, shuffle=False):\n",
    "        u_batch = x[u_ids, :]\n",
    "        u_batch = u_batch.A\n",
    "        u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n",
    "\n",
    "        theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "        bivae.mu_theta.data[u_ids] = u_mu.data\n",
    "\n",
    "    return bivae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiVAECF recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiVAECF(Recommender, ANNMixin):\n",
    "    \"\"\"Bilateral Variational AutoEncoder for Collaborative Filtering.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k: int, optional, default: 10\n",
    "        The dimension of the stochastic user ``theta'' and item ``beta'' factors.\n",
    "\n",
    "    encoder_structure: list, default: [20]\n",
    "        The number of neurons per layer of the user and item encoders for BiVAE.\n",
    "        For example, encoder_structure = [20], the user (item) encoder structure will be [num_items, 20, k] ([num_users, 20, k]).\n",
    "\n",
    "    act_fn: str, default: 'tanh'\n",
    "        Name of the activation function used between hidden layers of the auto-encoder.\n",
    "        Supported functions: ['sigmoid', 'tanh', 'elu', 'relu', 'relu6']\n",
    "\n",
    "    likelihood: str, default: 'pois'\n",
    "        The likelihood function used for modeling the observations.\n",
    "        Supported choices:\n",
    "\n",
    "        bern: Bernoulli likelihood\n",
    "        gaus: Gaussian likelihood\n",
    "        pois: Poisson likelihood\n",
    "\n",
    "    n_epochs: int, optional, default: 100\n",
    "        The number of epochs for SGD.\n",
    "\n",
    "    batch_size: int, optional, default: 100\n",
    "        The batch size.\n",
    "\n",
    "    learning_rate: float, optional, default: 0.001\n",
    "        The learning rate for Adam.\n",
    "\n",
    "    beta_kl: float, optional, default: 1.0\n",
    "        The weight of the KL terms as in beta-VAE.\n",
    "\n",
    "    cap_priors: dict, optional, default: {\"user\":False, \"item\":False}\n",
    "        When {\"user\":True, \"item\":True}, CAP priors are used (see BiVAE paper for details),\\\n",
    "        otherwise the standard Normal is used as a Prior over the user and item latent variables.\n",
    "\n",
    "    name: string, optional, default: 'BiVAECF'\n",
    "        The name of the recommender model.\n",
    "\n",
    "    trainable: boolean, optional, default: True\n",
    "        When False, the model is not trained and Cornac assumes that the model is already \\\n",
    "        pre-trained.\n",
    "\n",
    "    verbose: boolean, optional, default: False\n",
    "        When True, some running logs are displayed.\n",
    "\n",
    "    seed: int, optional, default: None\n",
    "        Random seed for parameters initialization.\n",
    "\n",
    "    use_gpu: boolean, optional, default: True\n",
    "        If True and your system supports CUDA then training is performed on GPUs.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    * Quoc-Tuan Truong, Aghiles Salah, Hady W. Lauw. \" Bilateral Variational Autoencoder for Collaborative Filtering.\"\n",
    "    ACM International Conference on Web Search and Data Mining (WSDM). 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=\"BiVAECF\",\n",
    "        k=10,\n",
    "        user_encoder_structure=[20],\n",
    "        item_encoder_structure = [20],\n",
    "        act_fn=\"tanh\",\n",
    "        likelihood=\"pois\",\n",
    "        n_epochs=100,\n",
    "        batch_size=100,\n",
    "        learning_rate=0.001,\n",
    "        beta_kl=1.0,\n",
    "        cap_priors={\"user\": False, \"item\": False},\n",
    "        trainable=True,\n",
    "        verbose=False,\n",
    "        seed=None,\n",
    "        use_gpu=True,\n",
    "    ):\n",
    "        Recommender.__init__(self, name=name, trainable=trainable, verbose=verbose)\n",
    "        self.k = k\n",
    "        self.user_encoder_structure = user_encoder_structure\n",
    "        self.item_encoder_structure = item_encoder_structure\n",
    "        self.act_fn = act_fn\n",
    "        self.likelihood = likelihood\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_kl = beta_kl\n",
    "        self.cap_priors = cap_priors\n",
    "        self.seed = seed\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "\n",
    "    def fit(self, train_set, val_set=None):\n",
    "        \"\"\"Fit the model to observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_set: :obj:`cornac.data.Dataset`, required\n",
    "            User-Item preference data as well as additional modalities.\n",
    "\n",
    "        val_set: :obj:`cornac.data.Dataset`, optional, default: None\n",
    "            User-Item preference data for model selection purposes (e.g., early stopping).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        Recommender.fit(self, train_set, val_set)\n",
    "\n",
    "        import torch\n",
    "        # from .bivae import BiVAE, learn\n",
    "        self.device = (\n",
    "            torch.device(\"cuda:0\")\n",
    "            if (self.use_gpu and torch.cuda.is_available())\n",
    "            else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "        if self.trainable:\n",
    "            feature_dim = {\"user\": None, \"item\": None}\n",
    "            if self.cap_priors.get(\"user\", False):\n",
    "                if train_set.user_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for users is set to True but no user features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"user\"] = train_set.user_feature.feature_dim\n",
    "\n",
    "            if self.cap_priors.get(\"item\", False):\n",
    "                if train_set.item_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for items is set to True but no item features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"item\"] = train_set.item_feature.feature_dim\n",
    "\n",
    "            if self.seed is not None:\n",
    "                torch.manual_seed(self.seed)\n",
    "                torch.cuda.manual_seed(self.seed)\n",
    "\n",
    "            if not hasattr(self, \"bivae\"):\n",
    "                num_items = train_set.matrix.shape[1]\n",
    "                num_users = train_set.matrix.shape[0]\n",
    "                self.bivae = BiVAE(\n",
    "                    k=self.k,\n",
    "                    user_encoder_structure=[num_items] + self.user_encoder_structure,\n",
    "                    item_encoder_structure=[num_users] + self.item_encoder_structure,\n",
    "                    act_fn=self.act_fn,\n",
    "                    likelihood=self.likelihood,\n",
    "                    cap_priors=self.cap_priors,\n",
    "                    feature_dim=feature_dim,\n",
    "                    batch_size=self.batch_size,\n",
    "                ).to(self.device)\n",
    "\n",
    "            learn(\n",
    "                self.bivae,\n",
    "                train_set,\n",
    "                n_epochs=self.n_epochs,\n",
    "                batch_size=self.batch_size,\n",
    "                learn_rate=self.learning_rate,\n",
    "                beta_kl=self.beta_kl,\n",
    "                verbose=self.verbose,\n",
    "                device=self.device,\n",
    "            )\n",
    "        elif self.verbose:\n",
    "            print(\"%s is trained already (trainable = False)\" % (self.name))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def score(self, user_idx, item_idx=None):\n",
    "        \"\"\"Predict the scores/ratings of a user for an item.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_idx: int, required\n",
    "            The index of the user for whom to perform score prediction.\n",
    "\n",
    "        item_idx: int, optional, default: None\n",
    "            The index of the item for which to perform score prediction.\n",
    "            If None, scores for all known items will be returned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        res : A scalar or a Numpy array\n",
    "            Relative scores that the user gives to the item or to all known items\n",
    "\n",
    "        \"\"\"\n",
    "        if self.is_unknown_user(user_idx):\n",
    "            raise ScoreException(\"Can't make score prediction for user %d\" % user_idx)\n",
    "\n",
    "        if item_idx is not None and self.is_unknown_item(item_idx):\n",
    "            raise ScoreException(\"Can't make score prediction for item %d\" % item_idx)\n",
    "\n",
    "        if item_idx is None:\n",
    "            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            beta = self.bivae.mu_beta\n",
    "            return self.bivae.decode_user(theta_u, beta).cpu().numpy().ravel()\n",
    "        else:\n",
    "            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            beta_i = self.bivae.mu_beta[item_idx].view(1, -1)\n",
    "            pred = self.bivae.decode_user(theta_u, beta_i).cpu().numpy().ravel()\n",
    "            return scale(pred, self.min_rating, self.max_rating, 0.0, 1.0)\n",
    "\n",
    "\n",
    "    def get_vector_measure(self):\n",
    "        \"\"\"Getting a valid choice of vector measurement in ANNMixin._measures.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        measure: MEASURE_DOT\n",
    "            Dot product aka. inner product\n",
    "        \"\"\"\n",
    "        return MEASURE_DOT\n",
    "\n",
    "\n",
    "    def get_user_vectors(self):\n",
    "        \"\"\"Getting a matrix of user vectors serving as query for ANN search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: numpy.array\n",
    "            Matrix of user vectors for all users available in the model.\n",
    "        \"\"\"\n",
    "        user_vectors = self.bivae.mu_theta.detach().cpu().numpy()\n",
    "        return user_vectors\n",
    "\n",
    "\n",
    "    def get_item_vectors(self):\n",
    "        \"\"\"Getting a matrix of item vectors used for building the index for ANN search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: numpy.array\n",
    "            Matrix of item vectors for all items available in the model.\n",
    "        \"\"\"\n",
    "        item_vectors = self.bivae.mu_beta.detach().cpu().numpy()\n",
    "        return item_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking(\n",
    "    model,\n",
    "    data,\n",
    "    usercol='userID',\n",
    "    itemcol='itemID',\n",
    "    predcol='pred',\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n",
    "    It can be used for computing ranking metrics like NDCG.\n",
    "\n",
    "    Args:\n",
    "        model (cornac.models.Recommender): A recommender model from Cornac\n",
    "        data (pandas.DataFrame): The data from which to get the users and items\n",
    "        usercol (str): Name of the user column\n",
    "        itemcol (str): Name of the item column\n",
    "        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(model.iid_map.keys())\n",
    "    for uid, user_idx in model.uid_map.items():\n",
    "        user = [uid] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(model.score(user_idx).tolist())\n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={usercol: users, itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                data[[usercol, itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking_user(\n",
    "    model,\n",
    "    data,\n",
    "    user_id,\n",
    "    usercol='userID',\n",
    "    itemcol='itemID',\n",
    "    predcol='pred',\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n",
    "    It can be used for computing ranking metrics like NDCG.\n",
    "\n",
    "    Args:\n",
    "        model (cornac.models.Recommender): A recommender model from Cornac\n",
    "        data (pandas.DataFrame): The data from which to get the users and items\n",
    "        usercol (str): Name of the user column\n",
    "        itemcol (str): Name of the item column\n",
    "        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(model.iid_map.keys())\n",
    "    # reverse_uid_map = {val : key for key,val in dict(model_.uid_map).items()}\n",
    "    user_idx = dict(model_.uid_map).get(user_id)\n",
    "\n",
    "    user_data = data.loc[data[usercol] == user_id]\n",
    "\n",
    "    # user = [uid] * len(item)\n",
    "    # users.extend(user)\n",
    "    items.extend(item)\n",
    "    preds.extend(model.score(user_idx).tolist())\n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                user_data[[itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(user_data.shape[0]), columns=[\"dummycol\"], index=user_data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_new_user(\n",
    "        symbols, \n",
    "        model_,\n",
    "        itemcol='itemID',\n",
    "        predcol='pred',\n",
    "        remove_seen=False,\n",
    "        ):\n",
    "\n",
    "\n",
    "    user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n",
    "    user_vec = np.zeros(len(model_.iid_map.keys()))\n",
    "    user_vec[user_symbol_idx] =1\n",
    "    \n",
    "    user_encoder = model_.bivae.user_encoder\n",
    "\n",
    "    user_mu = model_.bivae.user_mu\n",
    "    user_ten = torch.from_numpy(user_vec)\n",
    "    user_ten = user_ten.to(\"cuda:0\").float()\n",
    "\n",
    "    user_lat_vec = user_mu(user_encoder(user_ten)).view(1,-1)\n",
    "\n",
    "    beta_mu = model_.bivae.mu_beta\n",
    "\n",
    "    preds = model_.bivae.decode_user(user_lat_vec, beta_mu)\n",
    "    preds = preds.detach().cpu().numpy().ravel()\n",
    "    \n",
    "    items = list(model_.iid_map.keys())\n",
    "    all_predictions = pd.DataFrame(data = {itemcol:items})\n",
    "    \n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(data = symbols, columns = [itemcol]), \n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(len(symbols)), columns=[\"dummycol\"]\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# score_new_user_gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_new_user_gradio(\n",
    "        symbols, \n",
    "        model_ = model_,\n",
    "        itemcol='itemID',\n",
    "        predcol='pred',\n",
    "        remove_seen=False,\n",
    "        top_k = 10\n",
    "        ):\n",
    "\n",
    "\n",
    "    user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n",
    "    user_vec = np.zeros(len(model_.iid_map.keys()))\n",
    "    user_vec[user_symbol_idx] =1\n",
    "    \n",
    "    user_encoder = model_.bivae.user_encoder\n",
    "\n",
    "    user_mu = model_.bivae.user_mu\n",
    "    user_ten = torch.from_numpy(user_vec)\n",
    "    user_ten = user_ten.to(\"cuda:0\").float()\n",
    "\n",
    "    user_lat_vec = user_mu(user_encoder(user_ten)).view(1,-1)\n",
    "\n",
    "    beta_mu = model_.bivae.mu_beta\n",
    "\n",
    "    preds = model_.bivae.decode_user(user_lat_vec, beta_mu)\n",
    "    preds = preds.detach().cpu().numpy().ravel()\n",
    "    \n",
    "    items = list(model_.iid_map.keys())\n",
    "    # all_predictions = pd.DataFrame(data = {itemcol:items})\n",
    "    \n",
    "\n",
    "    all_preds = pd.DataFrame(\n",
    "        data={itemcol: items, predcol: preds}\n",
    "    )\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(data = symbols, columns = [itemcol]), \n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(len(symbols)), columns=[\"dummycol\"]\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_preds, on=[itemcol], how=\"outer\")\n",
    "        all_preds = merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "        top_k_symbols = list(all_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n",
    "        top_k_out = '\\n'.join(top_k_symbols)\n",
    "        return top_k_out\n",
    "    else:\n",
    "        top_k_symbols = list(all_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n",
    "        top_k_out = '\\n'.join(top_k_symbols)\n",
    "        return top_k_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"../../vector_db/phase3_symbols\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(query, top_k):\n",
    "  relevant_stocks = new_db.similarity_search_with_relevance_scores(query= query, k = top_k)\n",
    "  recommendations = [(relevant_stocks[idx][0].metadata.get('symbol'), relevant_stocks[idx][0].metadata.get('name'), relevant_stocks[idx][1]) for idx in range(len(relevant_stocks))]\n",
    "  for idx, data in enumerate(recommendations):\n",
    "    if data[2]>=0:\n",
    "      print('{}. {} : {} |score : {}'.format(idx+1, data[0], data[1], data[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_symbols(query, top_k):\n",
    "    \n",
    "    relevant_stocks = new_db.similarity_search_with_relevance_scores(query = query, k = top_k)\n",
    "    recommendations = [(relevant_stocks[idx][0].metadata.get('symbol'), relevant_stocks[idx][0].metadata.get('name'), relevant_stocks[idx][1]) for idx in range(len(relevant_stocks))]\n",
    "    \n",
    "    reco_count = 0\n",
    "    reco_symbols = []\n",
    "    for idx, data in enumerate(recommendations):\n",
    "        if data[2] >= 0:\n",
    "            reco_symbols.append(data[0])\n",
    "            reco_count += 1\n",
    "\n",
    "        else:\n",
    "            if reco_count <4:\n",
    "                reco_symbols.append(data[0])\n",
    "                reco_count += 1\n",
    "\n",
    "    return reco_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\langchain_core\\vectorstores.py:311: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content=\"E - CHANNELLING PLC digital lifestyle solutions for healthcare and other industries of Sri Lanka. The Company's main product is a software system, which provides channeling of medical practitioners.\\xa0\", metadata={'symbol': 'ECL', 'name': 'E - CHANNELLING PLC'}), 0.1030208233349047), (Document(page_content='SRI LANKA TELECOM PLC \\xa0information and communications technology (ICT) solutions provider. The Company is primarily involved in providing a portfolio of telecommunication services across Sri Lanka. In addition, the range of services provided by the Company include, inter-alia, Internet services, data services, domestic and international leased circuits, broadband, satellite uplink, maritime transmission, IPTV service and directory publishing service.', metadata={'symbol': 'SLTL', 'name': 'SRI LANKA TELECOM PLC'}), 0.005522012912471452), (Document(page_content='GESTETNER OF CEYLON PLC importing and selling of digital copiers, digital duplicators, duplicators, laser printers, laptops and air conditioners.', metadata={'symbol': 'GEST', 'name': 'GESTETNER OF CEYLON PLC'}), -0.005805374093316384), (Document(page_content=\"hSenid Business Solutions PLC development of human capital management (HCM) software products and related services. The Company's offerings include a comprehensive human resource information system (HRIS) solution known as the PeoplesHR platform as well as additional solutions such as PeoplesHR Outsourcing and Tracking Solutions.\", metadata={'symbol': 'HBS', 'name': 'hSenid Business Solutions PLC'}), -0.06668666535469692), (Document(page_content='DIALOG AXIATA PLC provide communication services, such as mobile, fixed, broadband, international gateway services; telecommunication infrastructure services, such as tower infrastructure and transmission services; media, such as digital television services based on multiple media- satellite, cable, terrestrial; digital services, including but not limited to digital commerce mobile and eCommerce; electronic payments, including mobile payment; digital health, education, navigation and enterprise services and financial services; software solutions, data center services, manpower services, provision of Information Technology and venture capital investment activities.', metadata={'symbol': 'DIAL', 'name': 'DIALOG AXIATA PLC'}), -0.09452010693650337), (Document(page_content='LAUGFS POWER PLC power and energy, consumer retail, industrial, services, leisure and logistics', metadata={'symbol': 'LPL', 'name': 'LAUGFS POWER PLC'}), -0.12714783683012088), (Document(page_content='ACCESS ENGINEERING PLC civil engineering and construction company. It operates through four segments: Construction, Construction-related materials, Property and Automobile.\\xa0', metadata={'symbol': 'AEL', 'name': 'ACCESS ENGINEERING PLC'}), -0.1678382588438725), (Document(page_content='EXTERMINATORS PLC an environmental enhancement technology company, engages in the provision of pest control services and related products', metadata={'symbol': 'EXT', 'name': 'EXTERMINATORS PLC'}), -0.1701838152572006), (Document(page_content='ABANS ELECTRICALS PLC manufacturing, assembling and installation of selected consumer durable products, provision of repair and maintenance services for a wider range of household electric and electronic appliances and installation of roof top Solar photovoltaic (PV) Systems.', metadata={'symbol': 'ABAN', 'name': 'ABANS ELECTRICALS PLC'}), -0.1911193350243201), (Document(page_content='DANKOTUWA PORCELAIN PLC manufacturing and marketing of porcelain tableware, targeted to export and domestic markets.', metadata={'symbol': 'DPL', 'name': 'DANKOTUWA PORCELAIN PLC'}), -0.1944094866064745)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ECL', 'SLTL', 'GEST', 'HBS']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_pref = 'technology'\n",
    "\n",
    "reco_symbols = text_to_symbols(stock_pref, top_k = 10)\n",
    "reco_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = r'../models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl'\n",
    "save_loc = r'..\\..\\models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl'\n",
    "model_ = BiVAECF.load(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72, 155,  67, 205, 240,  41])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = ['SHOT','SFIN', 'LCBF', 'MAL', 'TANG', 'ASIY']\n",
    "user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n",
    "user_vec = np.zeros(len(model_.iid_map.keys()))\n",
    "user_symbol_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec[user_symbol_idx] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.itemID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['SHOT','SFIN', 'LCBF', 'MAL', 'TANG', 'ASIY']\n",
    "\n",
    "new_user_preds = score_new_user(\n",
    "    symbols, \n",
    "    model_,\n",
    "    itemcol='itemID',\n",
    "    predcol='pred',\n",
    "    remove_seen=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_user_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIL', 'EXPO', 'LIOC', 'ACL', 'LOFC']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_user_preds.sort_values(by = 'pred', ascending= False).itemID.iloc[:5].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df.itemID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn = score_new_user_gradio,\n",
    "    inputs = gr.Dropdown(\n",
    "            # list(df.itemID.values),\n",
    "             multiselect=True,\n",
    "             label=\"symbols\",\n",
    "             allow_custom_value = False,\n",
    "             scale=5\n",
    "        ),\n",
    "    outputs = [\"text\"],\n",
    ")\n",
    "demo.launch(share = True)\n",
    "\n",
    "# businesses in the domain of shipping and logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tr_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
