{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import json\n",
    "# import io \n",
    "import sys\n",
    "# from PIL import Image\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"../../vector_db/phase2_symbols\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(query, top_k):\n",
    "  relevant_stocks = new_db.similarity_search_with_relevance_scores(query= query, k = top_k)\n",
    "  recommendations = [(relevant_stocks[idx][0].metadata.get('symbol'), relevant_stocks[idx][0].metadata.get('name'), relevant_stocks[idx][1]) for idx in range(len(relevant_stocks))]\n",
    "  for idx, data in enumerate(recommendations):\n",
    "    if data[2]>=0:\n",
    "      print('{}. {} : {} |score : {}'.format(idx+1, data[0], data[1], data[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ECL : E - CHANNELLING PLC |score : 0.15225744611490732\n",
      "2. SLTL : SRI LANKA TELECOM PLC |score : 0.1514007692720748\n",
      "3. GEST : GESTETNER OF CEYLON PLC |score : 0.09990819427867814\n",
      "4. HAYL : HAYLEYS PLC |score : 0.0751765921598796\n",
      "5. DIAL : DIALOG AXIATA PLC |score : 0.07034462456549961\n",
      "6. LPL : LAUGFS POWER PLC |score : 0.06791991637066785\n",
      "7. DIMO : DIESEL & MOTOR ENGINEERING PLC |score : 0.06789513402374348\n",
      "8. HBS : hSenid Business Solutions PLC |score : 0.06200249883973841\n",
      "9. MELS : MELSTACORP PLC |score : 0.060525841855310736\n",
      "10. MDL : MYLAND DEVELOPMENTS PLC |score : 0.05051326793566868\n"
     ]
    }
   ],
   "source": [
    "stock_pref = 'businesses in the domain of software and Inforamation technology'\n",
    "\n",
    "get_recommendations(stock_pref, top_k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from cornac.models.recommender import Recommender\n",
    "from cornac.utils.common import scale\n",
    "from cornac.exception import ScoreException\n",
    "\n",
    "from cornac.models.recommender import ANNMixin, MEASURE_DOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cornac 1.18 BiVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bivae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import trange\n",
    "\n",
    "\n",
    "EPS = 1e-10\n",
    "\n",
    "ACT = {\n",
    "    \"sigmoid\": nn.Sigmoid(),\n",
    "    \"tanh\": nn.Tanh(),\n",
    "    \"elu\": nn.ELU(),\n",
    "    \"relu\": nn.ReLU(),\n",
    "    \"relu6\": nn.ReLU6(),\n",
    "}\n",
    "\n",
    "\n",
    "class BiVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k,\n",
    "        user_encoder_structure,\n",
    "        item_encoder_structure,\n",
    "        act_fn,\n",
    "        likelihood,\n",
    "        cap_priors,\n",
    "        feature_dim,\n",
    "        batch_size,\n",
    "    ):\n",
    "        super(BiVAE, self).__init__()\n",
    "\n",
    "        self.mu_theta = torch.zeros((item_encoder_structure[0], k))  # n_users*k\n",
    "        self.mu_beta = torch.zeros((user_encoder_structure[0], k))  # n_items*k\n",
    "\n",
    "        self.theta = torch.randn(item_encoder_structure[0], k) * 0.01\n",
    "        self.beta = torch.randn(user_encoder_structure[0], k) * 0.01\n",
    "        torch.nn.init.kaiming_uniform_(self.theta, a=np.sqrt(5))\n",
    "\n",
    "        self.likelihood = likelihood\n",
    "        self.act_fn = ACT.get(act_fn, None)\n",
    "        if self.act_fn is None:\n",
    "            raise ValueError(\"Supported act_fn: {}\".format(ACT.keys()))\n",
    "\n",
    "        self.cap_priors = cap_priors\n",
    "        if self.cap_priors.get(\"user\", False):\n",
    "            self.user_prior_encoder = nn.Linear(feature_dim.get(\"user\"), k)\n",
    "        if self.cap_priors.get(\"item\", False):\n",
    "            self.item_prior_encoder = nn.Linear(feature_dim.get(\"item\"), k)\n",
    "\n",
    "        # User Encoder\n",
    "        self.user_encoder = nn.Sequential()\n",
    "        for i in range(len(user_encoder_structure) - 1):\n",
    "            self.user_encoder.add_module(\n",
    "                \"fc{}\".format(i),\n",
    "                nn.Linear(user_encoder_structure[i], user_encoder_structure[i + 1]),\n",
    "            )\n",
    "            self.user_encoder.add_module(\"act{}\".format(i), self.act_fn)\n",
    "        self.user_mu = nn.Linear(user_encoder_structure[-1], k)  # mu\n",
    "        self.user_std = nn.Linear(user_encoder_structure[-1], k)\n",
    "\n",
    "        # Item Encoder\n",
    "        self.item_encoder = nn.Sequential()\n",
    "        for i in range(len(item_encoder_structure) - 1):\n",
    "            self.item_encoder.add_module(\n",
    "                \"fc{}\".format(i),\n",
    "                nn.Linear(item_encoder_structure[i], item_encoder_structure[i + 1]),\n",
    "            )\n",
    "            self.item_encoder.add_module(\"act{}\".format(i), self.act_fn)\n",
    "        self.item_mu = nn.Linear(item_encoder_structure[-1], k)  # mu\n",
    "        self.item_std = nn.Linear(item_encoder_structure[-1], k)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.beta = self.beta.to(device=device)\n",
    "        self.theta = self.theta.to(device=device)\n",
    "        self.mu_beta = self.mu_beta.to(device=device)\n",
    "        self.mu_theta = self.mu_theta.to(device=device)\n",
    "        return super(BiVAE, self).to(device)\n",
    "\n",
    "    def encode_user_prior(self, x):\n",
    "        h = self.user_prior_encoder(x)\n",
    "        return h\n",
    "\n",
    "    def encode_item_prior(self, x):\n",
    "        h = self.item_prior_encoder(x)\n",
    "        return h\n",
    "\n",
    "    def encode_user(self, x):\n",
    "        h = self.user_encoder(x)\n",
    "        return self.user_mu(h), torch.sigmoid(self.user_std(h))\n",
    "\n",
    "    def encode_item(self, x):\n",
    "        h = self.item_encoder(x)\n",
    "        return self.item_mu(h), torch.sigmoid(self.item_std(h))\n",
    "\n",
    "    def decode_user(self, theta, beta):\n",
    "        h = theta.mm(beta.t())\n",
    "        return torch.sigmoid(h)\n",
    "\n",
    "    def decode_item(self, theta, beta):\n",
    "        h = beta.mm(theta.t())\n",
    "        return torch.sigmoid(h)\n",
    "\n",
    "    def reparameterize(self, mu, std):\n",
    "        eps = torch.randn_like(mu)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, user=True, beta=None, theta=None):\n",
    "\n",
    "        if user:\n",
    "            mu, std = self.encode_user(x)\n",
    "            theta = self.reparameterize(mu, std)\n",
    "            return theta, self.decode_user(theta, beta), mu, std\n",
    "        else:\n",
    "            mu, std = self.encode_item(x)\n",
    "            beta = self.reparameterize(mu, std)\n",
    "            return beta, self.decode_item(theta, beta), mu, std\n",
    "\n",
    "    def loss(self, x, x_, mu, mu_prior, std, kl_beta):\n",
    "        # Likelihood\n",
    "        ll_choices = {\n",
    "            \"bern\": x * torch.log(x_ + EPS) + (1 - x) * torch.log(1 - x_ + EPS),\n",
    "            \"gaus\": -(x - x_) ** 2,\n",
    "            \"pois\": x * torch.log(x_ + EPS) - x_,\n",
    "        }\n",
    "\n",
    "        ll = ll_choices.get(self.likelihood, None)\n",
    "        if ll is None:\n",
    "            raise ValueError(\"Supported likelihoods: {}\".format(ll_choices.keys()))\n",
    "\n",
    "        ll = torch.sum(ll, dim=1)\n",
    "\n",
    "        # KL term\n",
    "        kld = -0.5 * (1 + 2.0 * torch.log(std) - (mu - mu_prior).pow(2) - std.pow(2))\n",
    "        kld = torch.sum(kld, dim=1)\n",
    "\n",
    "        return torch.mean(kl_beta * kld - ll)\n",
    "\n",
    "\n",
    "def learn(\n",
    "    bivae,\n",
    "    train_set,\n",
    "    n_epochs,\n",
    "    batch_size,\n",
    "    learn_rate,\n",
    "    beta_kl,\n",
    "    verbose,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    dtype=torch.float32,\n",
    "):\n",
    "    user_params = it.chain(\n",
    "        bivae.user_encoder.parameters(),\n",
    "        bivae.user_mu.parameters(),\n",
    "        bivae.user_std.parameters(),\n",
    "    )\n",
    "\n",
    "    item_params = it.chain(\n",
    "        bivae.item_encoder.parameters(),\n",
    "        bivae.item_mu.parameters(),\n",
    "        bivae.item_std.parameters(),\n",
    "    )\n",
    "\n",
    "    if bivae.cap_priors.get(\"user\", False):\n",
    "        user_params = it.chain(user_params, bivae.user_prior_encoder.parameters())\n",
    "        user_features = train_set.user_feature.features[: train_set.num_users]\n",
    "\n",
    "    if bivae.cap_priors.get(\"item\", False):\n",
    "        item_params = it.chain(item_params, bivae.item_prior_encoder.parameters())\n",
    "        item_features = train_set.item_feature.features[: train_set.num_items]\n",
    "\n",
    "    u_optimizer = torch.optim.Adam(params=user_params, lr=learn_rate)\n",
    "    i_optimizer = torch.optim.Adam(params=item_params, lr=learn_rate)\n",
    "\n",
    "    x = train_set.matrix.copy()\n",
    "    x.data = np.ones_like(x.data)  # Binarize data\n",
    "    tx = x.transpose()\n",
    "\n",
    "    progress_bar = trange(1, n_epochs + 1, disable=not verbose)\n",
    "    for _ in progress_bar:\n",
    "        # item side\n",
    "        i_sum_loss = 0.0\n",
    "        i_count = 0\n",
    "        for i_ids in train_set.item_iter(batch_size, shuffle=False):\n",
    "            i_batch = tx[i_ids, :]\n",
    "            i_batch = i_batch.A\n",
    "            i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n",
    "\n",
    "            # Reconstructed batch\n",
    "            beta, i_batch_, i_mu, i_std = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "\n",
    "            i_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n",
    "            if bivae.cap_priors.get(\"item\", False):\n",
    "                i_batch_f = item_features[i_ids]\n",
    "                i_batch_f = torch.tensor(i_batch_f, dtype=dtype, device=device)\n",
    "                i_mu_prior = bivae.encode_item_prior(i_batch_f)\n",
    "\n",
    "            i_loss = bivae.loss(i_batch, i_batch_, i_mu, i_mu_prior, i_std, beta_kl)\n",
    "            i_optimizer.zero_grad()\n",
    "            i_loss.backward()\n",
    "            i_optimizer.step()\n",
    "\n",
    "            i_sum_loss += i_loss.data.item()\n",
    "            i_count += len(i_batch)\n",
    "\n",
    "            beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "\n",
    "            bivae.beta.data[i_ids] = beta.data\n",
    "            bivae.mu_beta.data[i_ids] = i_mu.data\n",
    "\n",
    "        # user side\n",
    "        u_sum_loss = 0.0\n",
    "        u_count = 0\n",
    "        for u_ids in train_set.user_iter(batch_size, shuffle=False):\n",
    "            u_batch = x[u_ids, :]\n",
    "            u_batch = u_batch.A\n",
    "            u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n",
    "\n",
    "            # Reconstructed batch\n",
    "            theta, u_batch_, u_mu, u_std = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "\n",
    "            u_mu_prior = 0.0  # zero mean for standard normal prior if not CAP prior\n",
    "            if bivae.cap_priors.get(\"user\", False):\n",
    "                u_batch_f = user_features[u_ids]\n",
    "                u_batch_f = torch.tensor(u_batch_f, dtype=dtype, device=device)\n",
    "                u_mu_prior = bivae.encode_user_prior(u_batch_f)\n",
    "\n",
    "            u_loss = bivae.loss(u_batch, u_batch_, u_mu, u_mu_prior, u_std, beta_kl)\n",
    "            u_optimizer.zero_grad()\n",
    "            u_loss.backward()\n",
    "            u_optimizer.step()\n",
    "\n",
    "            u_sum_loss += u_loss.data.item()\n",
    "            u_count += len(u_batch)\n",
    "\n",
    "            theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "            bivae.theta.data[u_ids] = theta.data\n",
    "            bivae.mu_theta.data[u_ids] = u_mu.data\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss_i=(i_sum_loss / i_count), loss_u=(u_sum_loss / (u_count))\n",
    "            )\n",
    "\n",
    "    # infer mu_beta\n",
    "    for i_ids in train_set.item_iter(batch_size, shuffle=False):\n",
    "        i_batch = tx[i_ids, :]\n",
    "        i_batch = i_batch.A\n",
    "        i_batch = torch.tensor(i_batch, dtype=dtype, device=device)\n",
    "\n",
    "        beta, _, i_mu, _ = bivae(i_batch, user=False, theta=bivae.theta)\n",
    "        bivae.mu_beta.data[i_ids] = i_mu.data\n",
    "\n",
    "    # infer mu_theta\n",
    "    for u_ids in train_set.user_iter(batch_size, shuffle=False):\n",
    "        u_batch = x[u_ids, :]\n",
    "        u_batch = u_batch.A\n",
    "        u_batch = torch.tensor(u_batch, dtype=dtype, device=device)\n",
    "\n",
    "        theta, _, u_mu, _ = bivae(u_batch, user=True, beta=bivae.beta)\n",
    "        bivae.mu_theta.data[u_ids] = u_mu.data\n",
    "\n",
    "    return bivae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiVAECF recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiVAECF(Recommender, ANNMixin):\n",
    "    \"\"\"Bilateral Variational AutoEncoder for Collaborative Filtering.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k: int, optional, default: 10\n",
    "        The dimension of the stochastic user ``theta'' and item ``beta'' factors.\n",
    "\n",
    "    encoder_structure: list, default: [20]\n",
    "        The number of neurons per layer of the user and item encoders for BiVAE.\n",
    "        For example, encoder_structure = [20], the user (item) encoder structure will be [num_items, 20, k] ([num_users, 20, k]).\n",
    "\n",
    "    act_fn: str, default: 'tanh'\n",
    "        Name of the activation function used between hidden layers of the auto-encoder.\n",
    "        Supported functions: ['sigmoid', 'tanh', 'elu', 'relu', 'relu6']\n",
    "\n",
    "    likelihood: str, default: 'pois'\n",
    "        The likelihood function used for modeling the observations.\n",
    "        Supported choices:\n",
    "\n",
    "        bern: Bernoulli likelihood\n",
    "        gaus: Gaussian likelihood\n",
    "        pois: Poisson likelihood\n",
    "\n",
    "    n_epochs: int, optional, default: 100\n",
    "        The number of epochs for SGD.\n",
    "\n",
    "    batch_size: int, optional, default: 100\n",
    "        The batch size.\n",
    "\n",
    "    learning_rate: float, optional, default: 0.001\n",
    "        The learning rate for Adam.\n",
    "\n",
    "    beta_kl: float, optional, default: 1.0\n",
    "        The weight of the KL terms as in beta-VAE.\n",
    "\n",
    "    cap_priors: dict, optional, default: {\"user\":False, \"item\":False}\n",
    "        When {\"user\":True, \"item\":True}, CAP priors are used (see BiVAE paper for details),\\\n",
    "        otherwise the standard Normal is used as a Prior over the user and item latent variables.\n",
    "\n",
    "    name: string, optional, default: 'BiVAECF'\n",
    "        The name of the recommender model.\n",
    "\n",
    "    trainable: boolean, optional, default: True\n",
    "        When False, the model is not trained and Cornac assumes that the model is already \\\n",
    "        pre-trained.\n",
    "\n",
    "    verbose: boolean, optional, default: False\n",
    "        When True, some running logs are displayed.\n",
    "\n",
    "    seed: int, optional, default: None\n",
    "        Random seed for parameters initialization.\n",
    "\n",
    "    use_gpu: boolean, optional, default: True\n",
    "        If True and your system supports CUDA then training is performed on GPUs.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    * Quoc-Tuan Truong, Aghiles Salah, Hady W. Lauw. \" Bilateral Variational Autoencoder for Collaborative Filtering.\"\n",
    "    ACM International Conference on Web Search and Data Mining (WSDM). 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=\"BiVAECF\",\n",
    "        k=10,\n",
    "        user_encoder_structure=[20],\n",
    "        item_encoder_structure = [20],\n",
    "        act_fn=\"tanh\",\n",
    "        likelihood=\"pois\",\n",
    "        n_epochs=100,\n",
    "        batch_size=100,\n",
    "        learning_rate=0.001,\n",
    "        beta_kl=1.0,\n",
    "        cap_priors={\"user\": False, \"item\": False},\n",
    "        trainable=True,\n",
    "        verbose=False,\n",
    "        seed=None,\n",
    "        use_gpu=True,\n",
    "    ):\n",
    "        Recommender.__init__(self, name=name, trainable=trainable, verbose=verbose)\n",
    "        self.k = k\n",
    "        self.user_encoder_structure = user_encoder_structure\n",
    "        self.item_encoder_structure = item_encoder_structure\n",
    "        self.act_fn = act_fn\n",
    "        self.likelihood = likelihood\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_kl = beta_kl\n",
    "        self.cap_priors = cap_priors\n",
    "        self.seed = seed\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "\n",
    "    def fit(self, train_set, val_set=None):\n",
    "        \"\"\"Fit the model to observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_set: :obj:`cornac.data.Dataset`, required\n",
    "            User-Item preference data as well as additional modalities.\n",
    "\n",
    "        val_set: :obj:`cornac.data.Dataset`, optional, default: None\n",
    "            User-Item preference data for model selection purposes (e.g., early stopping).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "        Recommender.fit(self, train_set, val_set)\n",
    "\n",
    "        import torch\n",
    "        # from .bivae import BiVAE, learn\n",
    "        self.device = (\n",
    "            torch.device(\"cuda:0\")\n",
    "            if (self.use_gpu and torch.cuda.is_available())\n",
    "            else torch.device(\"cpu\")\n",
    "        )\n",
    "\n",
    "        if self.trainable:\n",
    "            feature_dim = {\"user\": None, \"item\": None}\n",
    "            if self.cap_priors.get(\"user\", False):\n",
    "                if train_set.user_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for users is set to True but no user features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"user\"] = train_set.user_feature.feature_dim\n",
    "\n",
    "            if self.cap_priors.get(\"item\", False):\n",
    "                if train_set.item_feature is None:\n",
    "                    raise ValueError(\n",
    "                        \"CAP priors for items is set to True but no item features are provided\"\n",
    "                    )\n",
    "                else:\n",
    "                    feature_dim[\"item\"] = train_set.item_feature.feature_dim\n",
    "\n",
    "            if self.seed is not None:\n",
    "                torch.manual_seed(self.seed)\n",
    "                torch.cuda.manual_seed(self.seed)\n",
    "\n",
    "            if not hasattr(self, \"bivae\"):\n",
    "                num_items = train_set.matrix.shape[1]\n",
    "                num_users = train_set.matrix.shape[0]\n",
    "                self.bivae = BiVAE(\n",
    "                    k=self.k,\n",
    "                    user_encoder_structure=[num_items] + self.user_encoder_structure,\n",
    "                    item_encoder_structure=[num_users] + self.item_encoder_structure,\n",
    "                    act_fn=self.act_fn,\n",
    "                    likelihood=self.likelihood,\n",
    "                    cap_priors=self.cap_priors,\n",
    "                    feature_dim=feature_dim,\n",
    "                    batch_size=self.batch_size,\n",
    "                ).to(self.device)\n",
    "\n",
    "            learn(\n",
    "                self.bivae,\n",
    "                train_set,\n",
    "                n_epochs=self.n_epochs,\n",
    "                batch_size=self.batch_size,\n",
    "                learn_rate=self.learning_rate,\n",
    "                beta_kl=self.beta_kl,\n",
    "                verbose=self.verbose,\n",
    "                device=self.device,\n",
    "            )\n",
    "        elif self.verbose:\n",
    "            print(\"%s is trained already (trainable = False)\" % (self.name))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def score(self, user_idx, item_idx=None):\n",
    "        \"\"\"Predict the scores/ratings of a user for an item.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_idx: int, required\n",
    "            The index of the user for whom to perform score prediction.\n",
    "\n",
    "        item_idx: int, optional, default: None\n",
    "            The index of the item for which to perform score prediction.\n",
    "            If None, scores for all known items will be returned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        res : A scalar or a Numpy array\n",
    "            Relative scores that the user gives to the item or to all known items\n",
    "\n",
    "        \"\"\"\n",
    "        if self.is_unknown_user(user_idx):\n",
    "            raise ScoreException(\"Can't make score prediction for user %d\" % user_idx)\n",
    "\n",
    "        if item_idx is not None and self.is_unknown_item(item_idx):\n",
    "            raise ScoreException(\"Can't make score prediction for item %d\" % item_idx)\n",
    "\n",
    "        if item_idx is None:\n",
    "            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            beta = self.bivae.mu_beta\n",
    "            return self.bivae.decode_user(theta_u, beta).cpu().numpy().ravel()\n",
    "        else:\n",
    "            theta_u = self.bivae.mu_theta[user_idx].view(1, -1)\n",
    "            beta_i = self.bivae.mu_beta[item_idx].view(1, -1)\n",
    "            pred = self.bivae.decode_user(theta_u, beta_i).cpu().numpy().ravel()\n",
    "            return scale(pred, self.min_rating, self.max_rating, 0.0, 1.0)\n",
    "\n",
    "\n",
    "    def get_vector_measure(self):\n",
    "        \"\"\"Getting a valid choice of vector measurement in ANNMixin._measures.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        measure: MEASURE_DOT\n",
    "            Dot product aka. inner product\n",
    "        \"\"\"\n",
    "        return MEASURE_DOT\n",
    "\n",
    "\n",
    "    def get_user_vectors(self):\n",
    "        \"\"\"Getting a matrix of user vectors serving as query for ANN search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: numpy.array\n",
    "            Matrix of user vectors for all users available in the model.\n",
    "        \"\"\"\n",
    "        user_vectors = self.bivae.mu_theta.detach().cpu().numpy()\n",
    "        return user_vectors\n",
    "\n",
    "\n",
    "    def get_item_vectors(self):\n",
    "        \"\"\"Getting a matrix of item vectors used for building the index for ANN search.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: numpy.array\n",
    "            Matrix of item vectors for all items available in the model.\n",
    "        \"\"\"\n",
    "        item_vectors = self.bivae.mu_beta.detach().cpu().numpy()\n",
    "        return item_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking(\n",
    "    model,\n",
    "    data,\n",
    "    usercol='userID',\n",
    "    itemcol='itemID',\n",
    "    predcol='pred',\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n",
    "    It can be used for computing ranking metrics like NDCG.\n",
    "\n",
    "    Args:\n",
    "        model (cornac.models.Recommender): A recommender model from Cornac\n",
    "        data (pandas.DataFrame): The data from which to get the users and items\n",
    "        usercol (str): Name of the user column\n",
    "        itemcol (str): Name of the item column\n",
    "        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(model.iid_map.keys())\n",
    "    for uid, user_idx in model.uid_map.items():\n",
    "        user = [uid] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(model.score(user_idx).tolist())\n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={usercol: users, itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                data[[usercol, itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking_user(\n",
    "    model,\n",
    "    data,\n",
    "    user_id,\n",
    "    usercol='userID',\n",
    "    itemcol='itemID',\n",
    "    predcol='pred',\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n",
    "    It can be used for computing ranking metrics like NDCG.\n",
    "\n",
    "    Args:\n",
    "        model (cornac.models.Recommender): A recommender model from Cornac\n",
    "        data (pandas.DataFrame): The data from which to get the users and items\n",
    "        usercol (str): Name of the user column\n",
    "        itemcol (str): Name of the item column\n",
    "        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(model.iid_map.keys())\n",
    "    # reverse_uid_map = {val : key for key,val in dict(model_.uid_map).items()}\n",
    "    user_idx = dict(model_.uid_map).get(user_id)\n",
    "\n",
    "    user_data = data.loc[data[usercol] == user_id]\n",
    "\n",
    "    # user = [uid] * len(item)\n",
    "    # users.extend(user)\n",
    "    items.extend(item)\n",
    "    preds.extend(model.score(user_idx).tolist())\n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                user_data[[itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(user_data.shape[0]), columns=[\"dummycol\"], index=user_data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insight generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/phase_2/price_data_v2.xlsx'\n",
    "\n",
    "data = pd.read_excel(data_path, index_col= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECURITYCODE</th>\n",
       "      <th>OPENINGPRICE</th>\n",
       "      <th>HIGHPX</th>\n",
       "      <th>LOWPX</th>\n",
       "      <th>CLOSINGPRICE</th>\n",
       "      <th>TRADEDATE</th>\n",
       "      <th>UNIX_TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOP</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MDL</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCT</td>\n",
       "      <td>24.9</td>\n",
       "      <td>26.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.2</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HBS</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SECURITYCODE  OPENINGPRICE  HIGHPX  LOWPX  CLOSINGPRICE  TRADEDATE  \\\n",
       "0          EXT           7.3     7.5    7.3           7.5 2024-02-07   \n",
       "1         COOP           2.3     2.3    2.2           2.2 2024-02-07   \n",
       "2          MDL           8.3     8.6    8.3           8.6 2024-02-07   \n",
       "3          FCT          24.9    26.4   24.8          26.2 2024-02-07   \n",
       "4          HBS          11.5    11.6   11.5          11.5 2024-02-07   \n",
       "\n",
       "      UNIX_TS  \n",
       "0  1707264000  \n",
       "1  1707264000  \n",
       "2  1707264000  \n",
       "3  1707264000  \n",
       "4  1707264000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot OHLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ohlc(data, title):\n",
    "    x_vals = data.TRADEDATE\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, vertical_spacing=0.01 , specs=[[{'rowspan':1, 'type':'Candlestick'}]],shared_xaxes=True)\n",
    "    ohlc_obj = go.Candlestick(x=x_vals, open = data.OPENINGPRICE, high=data.HIGHPX, low=data.LOWPX, close=data.CLOSINGPRICE, name= title)\n",
    "    fig.add_trace(ohlc_obj, row = 1, col = 1)\n",
    "    fig.update_layout(title = title)\n",
    "    fig.show(config={\n",
    "        'modeBarButtonsToRemove': ['zoom', 'pan']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtle import bgcolor\n",
    "# from matplotlib.axis import XAxis\n",
    "\n",
    "\n",
    "def plot_ohlc_w_des(data, titile, des):\n",
    "    x_vals = data.TRADEDATE\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, vertical_spacing=0.01, column_widths=[0.15, 0.85], subplot_titles=[\"\", \"Chart\"]) #,shared_xaxes=True\n",
    "    ohlc_obj = go.Candlestick(x=x_vals, open = data.OPENINGPRICE, high=data.HIGHPX, low=data.LOWPX, close=data.CLOSINGPRICE, name= 'OHLC')\n",
    "    fig.add_trace(ohlc_obj, row = 1, col = 2)\n",
    "    fig.add_trace(go.Scatter(x=[], y=[]), row=1, col=1)\n",
    "\n",
    "    fig.add_annotation(x=10, y=10, xref=\"paper\", yref=\"paper\",\n",
    "                   text=des, showarrow=False,\n",
    "                   align = 'left',\n",
    "                   font=dict(size=10, color=\"black\"),\n",
    "                   row=1, col=1)\n",
    "\n",
    "    fig.update_layout(xaxis=dict(visible=False), yaxis=dict(visible=False))\n",
    "    fig.update_yaxes(showgrid=False, zeroline=False, showticklabels=False, row=1, col=1)\n",
    "    fig.update_annotations(selector=dict(row=1, col=1), paper_bgcolor='rgba(0,0,0,0)',plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(height=500, width=1500, title_text=titile)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from turtle import bgcolor\n",
    "# from matplotlib.axis import XAxis\n",
    "\n",
    "\n",
    "def plot_ohlc_v1(data):\n",
    "    x_vals = data.TRADEDATE\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1, vertical_spacing=0.01, specs=[[{'rowspan':1, 'type':'Candlestick'}]])\n",
    "    ohlc_obj = go.Candlestick(x=x_vals, open = data.OPENINGPRICE, high=data.HIGHPX, low=data.LOWPX, close=data.CLOSINGPRICE, name= 'OHLC')\n",
    "    fig.add_trace(ohlc_obj, row = 1, col = 1)\n",
    "\n",
    "    # fig.update_yaxes(showgrid=False, zeroline=False, showticklabels=False, row=1, col=1)\n",
    "    fig.update_layout(height=450, width=995)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHLC candles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_returns_v2(df ,close_col , horizon):\n",
    "  data1 = df[close_col][horizon:].to_numpy()\n",
    "  data2 = df[close_col][:-horizon].to_numpy()\n",
    "  df = df.reset_index(drop = True)\n",
    "  df.loc[horizon:, 'returns'] = data1/data2\n",
    "  df['log_returns'] = np.log(df['returns'])\n",
    "  df = df.dropna(axis = 0, how = 'any').reset_index(drop = True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_volatility(df, close_col = 'CLOSINGPRICE', horizon = 5):\n",
    "\n",
    "    df_out = get_log_returns_v2(df, 'CLOSINGPRICE', 5)\n",
    "    return_mean = df_out.log_returns.mean()\n",
    "    return_std = df_out.log_returns.std()\n",
    "\n",
    "    return return_mean, return_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garman Klass volatility\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GKHV(o,h,l,c):\n",
    "\n",
    "    volatility = (1/2)*((np.log(h/l))**2) + (2*(np.log(2))-1)*((np.log(c/o))**2)\n",
    "\n",
    "    return volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rogers and Satchell\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RS(o,h,l,c,prev_c):\n",
    "\n",
    "    u = np.log(h/o)\n",
    "    c = np.log(c/o)\n",
    "    d = np.log(l/o)\n",
    "\n",
    "\n",
    "    volatility = u*(u-c) + d*(d-c)\n",
    "\n",
    "    return volatility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yand and Zhang\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_volatilities = pd.DataFrame()\n",
    "v_dict = {}\n",
    "symbols = data\n",
    "for symbol in symbols:\n",
    "    # print(symbol)\n",
    "    v_dict['symbol'] = symbol\n",
    "\n",
    "    symbol_df = data.loc[data.SECURITYCODE == symbol].sort_values(by = 'UNIX_TS').reset_index(drop = True)\n",
    "    \n",
    "    symbol_df['gkhv'] = symbol_df.apply(lambda row: GKHV(row['OPENINGPRICE'],row['HIGHPX'],row['LOWPX'],row['CLOSINGPRICE']), axis = 1)\n",
    "    gkhv = np.sqrt(symbol_df.gkhv.mean())\n",
    "    v_dict['gkhv'] = gkhv\n",
    "\n",
    "    symbol_df['prev_c'] = symbol_df['CLOSINGPRICE'].shift(1)\n",
    "    symbol_df['rs'] = symbol_df.apply(lambda row: RS(row['OPENINGPRICE'],row['HIGHPX'],row['LOWPX'],row['CLOSINGPRICE'], row['prev_c']), axis = 1)\n",
    "    rs = np.sqrt(symbol_df.rs.mean())\n",
    "    v_dict['rs'] = rs\n",
    "\n",
    "    symbol_df['norm_o'] = symbol_df['OPENINGPRICE']/symbol_df['CLOSINGPRICE'].shift(1)\n",
    "    symbol_df['norm_c'] = symbol_df['CLOSINGPRICE']/symbol_df['OPENINGPRICE']\n",
    "    k = (0.34/(1.34 + ((len(symbol_df)+1)/(len(symbol_df)-1))))\n",
    "    yangzhang = np.sqrt((symbol_df['norm_o'].std()**2) + (k*symbol_df['norm_c'].std()**2) + (1-k)*symbol_df['rs'].mean())\n",
    "    v_dict['yangzhang'] = yangzhang\n",
    "\n",
    "    symbol_volatilities = pd.concat([symbol_volatilities, pd.DataFrame([v_dict])], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_volatlity_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volatility_insights(symbol_df):\n",
    "\n",
    "    symbol_df['gkhv'] = symbol_df.apply(lambda row: GKHV(row['OPENINGPRICE'],row['HIGHPX'],row['LOWPX'],row['CLOSINGPRICE']), axis = 1)\n",
    "    gkhv = (np.sqrt(symbol_df.gkhv.mean()))*100\n",
    "\n",
    "    symbol_df['prev_c'] = symbol_df['CLOSINGPRICE'].shift(1)\n",
    "    symbol_df['rs'] = symbol_df.apply(lambda row: RS(row['OPENINGPRICE'],row['HIGHPX'],row['LOWPX'],row['CLOSINGPRICE'], row['prev_c']), axis = 1)\n",
    "    rs = (np.sqrt(symbol_df.rs.mean()))*100\n",
    "\n",
    "    symbol_df['norm_o'] = symbol_df['OPENINGPRICE']/symbol_df['CLOSINGPRICE'].shift(1)\n",
    "    symbol_df['norm_c'] = symbol_df['CLOSINGPRICE']/symbol_df['OPENINGPRICE']\n",
    "    k = (0.34/(1.34 + ((len(symbol_df)+1)/(len(symbol_df)-1))))\n",
    "    \n",
    "    yangzhang = np.sqrt((symbol_df['norm_o'].std()**2) + (k*symbol_df['norm_c'].std()**2) + (1-k)*symbol_df['rs'].mean())*100\n",
    "    \n",
    "    return gkhv, rs, yangzhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drowdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns percentage\n",
    "def max_drowdown(symb_df,close):\n",
    "    max_prs = close.rolling(window = len(symb_df), min_periods = 1).max()\n",
    "    dd = (close/max_prs) - 1\n",
    "    max_dd = dd.rolling(window = len(dd), min_periods=1).min()\n",
    "    return max_dd.min()*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_act_fday(symbol_df ,possible_dates):\n",
    "\n",
    "    for pos_date in possible_dates:\n",
    "    # print(pos_date)\n",
    "        if pos_date in symbol_df.TRADEDATE.values:\n",
    "            return pos_date\n",
    "            # break\n",
    "    \n",
    "    # return pos_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_yr_2_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the percentage value\n",
    "def get_yr_2_date(symbol_df):\n",
    "    # fday = pd.Timestamp(datetime((pd.Timestamp.today().year),1,1).date())\n",
    "\n",
    "    # fixing current date as per the dataset. ideally should be the actual current date\n",
    "    fday = pd.Timestamp(datetime((symbol_df.TRADEDATE.max().year),1,1).date())\n",
    "\n",
    "    possible_dates = pd.bdate_range(fday, fday+pd.offsets.BusinessDay(n=5))\n",
    "\n",
    "    act_fday = find_act_fday(symbol_df,possible_dates)\n",
    "    \n",
    "    fday_value = symbol_df.loc[symbol_df.TRADEDATE == act_fday].CLOSINGPRICE.iloc[0]\n",
    "    today_value = symbol_df.iloc[-1].CLOSINGPRICE\n",
    "\n",
    "    yr_2_dt_return = (today_value - fday_value)/fday_value\n",
    "\n",
    "    yr_2_date_df = symbol_df[symbol_df.TRADEDATE >= act_fday].sort_values(by = 'UNIX_TS')\n",
    "    gkhv, rs, yangzhang = get_volatility_insights(yr_2_date_df)\n",
    "\n",
    "    max_dd = max_drowdown(yr_2_date_df, yr_2_date_df['CLOSINGPRICE'])\n",
    "\n",
    "    # return yr_2_dt_return*100, max_dd, gkhv, rs, yangzhang\n",
    "    return round(yr_2_dt_return*100, 2), round(max_dd, 2) , round(gkhv, 2), round(rs, 2), round(yangzhang, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the percentage value\n",
    "def get_yr(symbol_df):\n",
    "\n",
    "    fday = symbol_df.TRADEDATE.iloc[-1] - pd.DateOffset(years=1)\n",
    "    possible_dates = pd.bdate_range(fday, fday+pd.offsets.BusinessDay(n=20))\n",
    "    \n",
    "    act_fday = find_act_fday(symbol_df,possible_dates)\n",
    "    \n",
    "    fday_value = symbol_df.loc[symbol_df.TRADEDATE == act_fday].CLOSINGPRICE.iloc[0]\n",
    "    today_value = symbol_df.iloc[-1].CLOSINGPRICE\n",
    "\n",
    "    yr_return = (today_value - fday_value)/fday_value\n",
    "\n",
    "    yr_df = symbol_df[symbol_df.TRADEDATE >= act_fday].sort_values(by = 'UNIX_TS')\n",
    "    gkhv, rs, yangzhang = get_volatility_insights(yr_df)\n",
    "\n",
    "    max_dd = max_drowdown(yr_df, yr_df['CLOSINGPRICE'])\n",
    "\n",
    "    # return yr_return*100, max_dd, gkhv, rs, yangzhang\n",
    "    return round(yr_return*100, 2), round(max_dd, 2) , round(gkhv, 2), round(rs, 2), round(yangzhang, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the percentage value\n",
    "def get_mn(symbol_df):\n",
    "\n",
    "    fday = symbol_df.TRADEDATE.iloc[-1] - pd.DateOffset(months=1)\n",
    "    possible_dates = pd.bdate_range(fday, fday+pd.offsets.BusinessDay(n=5))\n",
    "\n",
    "    act_fday = find_act_fday(symbol_df,possible_dates)\n",
    "    \n",
    "    fday_value = symbol_df.loc[symbol_df.TRADEDATE == act_fday].CLOSINGPRICE.iloc[0]\n",
    "    today_value = symbol_df.iloc[-1].CLOSINGPRICE\n",
    "\n",
    "    mn_return = (today_value - fday_value)/fday_value\n",
    "\n",
    "    mn_df = symbol_df[symbol_df.TRADEDATE >= act_fday].sort_values(by = 'UNIX_TS')\n",
    "    gkhv, rs, yangzhang = get_volatility_insights(mn_df)\n",
    "\n",
    "    max_dd = max_drowdown(mn_df, mn_df['CLOSINGPRICE'])\n",
    "\n",
    "    return round(mn_return*100, 2), round(max_dd, 2) , round(gkhv, 2), round(rs, 2), round(yangzhang, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights(symbol):\n",
    "    insight_dict = {'year_to_date':{}, 'last_year':{}, 'last_month' : {}}\n",
    "    symbol_df = data.loc[data.SECURITYCODE == symbol].sort_values(by = 'UNIX_TS')\n",
    "\n",
    "    insight_dict['year_to_date']['yr_2_dt_return'], insight_dict['year_to_date']['yr_2_dt_mx_dd'], insight_dict['year_to_date']['gkhv'], insight_dict['year_to_date']['rs'], insight_dict['year_to_date']['yangzhang'] = get_yr_2_date(symbol_df)\n",
    "    insight_dict['last_year']['yr_2_dt_return'], insight_dict['last_year']['yr_2_dt_mx_dd'], insight_dict['last_year']['gkhv'], insight_dict['last_year']['rs'], insight_dict['last_year']['yangzhang'] = get_yr(symbol_df)\n",
    "    insight_dict['last_month']['yr_2_dt_return'], insight_dict['last_month']['yr_2_dt_mx_dd'], insight_dict['last_month']['gkhv'], insight_dict['last_month']['rs'], insight_dict['last_month']['yangzhang'] = get_mn(symbol_df)\n",
    "\n",
    "    return insight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights_html(symbol):\n",
    "    insight_dict = {'year_to_date':{}, 'last_year':{}, 'last_month' : {}}\n",
    "    symbol_df = data.loc[data.SECURITYCODE == symbol].sort_values(by = 'UNIX_TS')\n",
    "\n",
    "    y2d = get_yr_2_date(symbol_df)\n",
    "    yr = get_yr(symbol_df)\n",
    "    mn = get_mn(symbol_df)\n",
    "\n",
    "    desc = 'year to date : <br>'\\\n",
    "    '   return : {}%<br>'\\\n",
    "    '   max drow down : {}%<br>'\\\n",
    "    '   gkhv : {}%<br>'\\\n",
    "    '   rs : {}%<br>'\\\n",
    "    '   yangzhang : {}%<br>'\\\n",
    "    ' <br>'\\\n",
    "    'last year : <br>'\\\n",
    "    '   return : {}%<br>'\\\n",
    "    '   max drow down : {}%<br>'\\\n",
    "    '   gkhv : {}%<br>'\\\n",
    "    '   rs : {}%<br>'\\\n",
    "    '   yangzhang : {}%<br>'\\\n",
    "    ' <br>'\\\n",
    "    'last month : <br>'\\\n",
    "    '   return : {}%<br>'\\\n",
    "    '   max drow down : {}%<br>'\\\n",
    "    '   gkhv : {}%<br>'\\\n",
    "    '   rs : {}%<br>'\\\n",
    "    '   yangzhang : {}%<br>'.format(y2d[0],y2d[1],y2d[2],y2d[3],y2d[4],\n",
    "                        yr[0],yr[1],yr[2],yr[3],yr[4],\n",
    "                        mn[0],mn[1],mn[2],mn[3],mn[4])\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insights_str(symbol):\n",
    "    # insight_dict = {'year_to_date':{}, 'last_year':{}, 'last_month' : {}}\n",
    "    symbol_df = data.loc[data.SECURITYCODE == symbol].sort_values(by = 'UNIX_TS')\n",
    "\n",
    "    y2d = get_yr_2_date(symbol_df)\n",
    "    yr = get_yr(symbol_df)\n",
    "    mn = get_mn(symbol_df)\n",
    "  \n",
    "    return ([y2d[0],y2d[1],y2d[2],y2d[3],y2d[4],\n",
    "                        yr[0],yr[1],yr[2],yr[3],yr[4],\n",
    "                        mn[0],mn[1],mn[2],mn[3],mn[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SECURITYCODE</th>\n",
       "      <th>OPENINGPRICE</th>\n",
       "      <th>HIGHPX</th>\n",
       "      <th>LOWPX</th>\n",
       "      <th>CLOSINGPRICE</th>\n",
       "      <th>TRADEDATE</th>\n",
       "      <th>UNIX_TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOP</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>1707264000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SECURITYCODE  OPENINGPRICE  HIGHPX  LOWPX  CLOSINGPRICE  TRADEDATE  \\\n",
       "0          EXT           7.3     7.5    7.3           7.5 2024-02-07   \n",
       "1         COOP           2.3     2.3    2.2           2.2 2024-02-07   \n",
       "\n",
       "      UNIX_TS  \n",
       "0  1707264000  \n",
       "1  1707264000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data = data.copy()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = r'../models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl'\n",
    "save_loc = r'..\\..\\models\\BiVAECF_alldata_24_02_16_15_32\\BiVAECF\\2024-02-16_15-32-24-532947.pkl'\n",
    "model_ = BiVAECF.load(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_17212\\432685352.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stock_data['Symbol'] = stock_data['Symbol'].str.replace(r\"(\",\"\")\n",
      "C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_17212\\432685352.py:12: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stock_data['Symbol'] = stock_data['Symbol'].str.replace(r\")\",\"\")\n"
     ]
    }
   ],
   "source": [
    "stock_data_excel_file = pd.ExcelFile('../../data/phase_2/stock_data.xlsx')\n",
    "data_path = '../../data/phase_2/price_data_v2.xlsx'\n",
    "\n",
    "data = pd.read_excel(data_path, index_col= False)\n",
    "price_symbols = list(data.SECURITYCODE.unique())\n",
    "\n",
    "stock_data = pd.read_excel(stock_data_excel_file, 'phase 1 symbols reduced')\n",
    "\n",
    "stock_data = stock_data[stock_data.Symbol.isin(price_symbols)].copy()\n",
    "\n",
    "stock_data['Symbol'] = stock_data['Symbol'].str.replace(r\"(\",\"\")\n",
    "stock_data['Symbol'] = stock_data['Symbol'].str.replace(r\")\",\"\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "stock_meta_data = {stock_data.iloc[idx]['Symbol'] : stock_data.iloc[idx]['Name'] for idx in range(stock_data.shape[0])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quey_generator(domains):\n",
    "    # query = 'busines in the domain of '+','.join(domains)\n",
    "    query = ','.join(domains)\n",
    "    return query\n",
    "\n",
    "####\n",
    "def get_cf_recos(\n",
    "        symbols, \n",
    "        model_ = model_,\n",
    "        itemcol='itemID',\n",
    "        predcol='pred',\n",
    "        remove_seen=False,\n",
    "        top_k = 10,\n",
    "        val_symbols = price_symbols\n",
    "        ):\n",
    "\n",
    "\n",
    "    user_symbol_idx = np.array([model_.iid_map.get(symbol) for symbol in symbols])\n",
    "    user_vec = np.zeros(len(model_.iid_map.keys()))\n",
    "    user_vec[user_symbol_idx] =1\n",
    "    \n",
    "    user_encoder = model_.bivae.user_encoder\n",
    "\n",
    "    user_mu = model_.bivae.user_mu\n",
    "    user_ten = torch.from_numpy(user_vec)\n",
    "    user_ten = user_ten.to(\"cuda:0\").float()\n",
    "\n",
    "    user_lat_vec = user_mu(user_encoder(user_ten)).view(1,-1)\n",
    "\n",
    "    beta_mu = model_.bivae.mu_beta\n",
    "\n",
    "    preds = model_.bivae.decode_user(user_lat_vec, beta_mu)\n",
    "    preds = preds.detach().cpu().numpy().ravel()\n",
    "    \n",
    "    items = list(model_.iid_map.keys())\n",
    "    # all_predictions = pd.DataFrame(data = {itemcol:items})\n",
    "    \n",
    "\n",
    "    all_preds = pd.DataFrame(\n",
    "        data={itemcol: items, predcol: preds}\n",
    "    )\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame(data = symbols, columns = [itemcol]), \n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(len(symbols)), columns=[\"dummycol\"]\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_preds, on=[itemcol], how=\"outer\")\n",
    "        all_preds = merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "        # this is temp. need to only out put symbols of which we have price data to generate insights\n",
    "        all_preds_fil = all_preds[all_preds.itemID.isin(val_symbols)].copy()\n",
    "        top_k_symbols = list(all_preds_fil.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n",
    "        return top_k_symbols\n",
    "    else:\n",
    "        all_preds_fil = all_preds[all_preds.itemID.isin(val_symbols)].copy()\n",
    "        top_k_symbols = list(all_preds_fil.sort_values(by = 'pred', ascending= False).itemID.iloc[:top_k].values)\n",
    "        return top_k_symbols\n",
    "    \n",
    "\n",
    "####\n",
    "def get_recommendations_gradio_cf(domains, top_k = 5):\n",
    "    query = quey_generator(domains)\n",
    "    relevant_stocks = new_db.similarity_search_with_relevance_scores(query= query, k = top_k)\n",
    "    recommendations = [(relevant_stocks[idx][0].metadata.get('symbol'), relevant_stocks[idx][0].metadata.get('name'), relevant_stocks[idx][1]) for idx in range(len(relevant_stocks))]\n",
    "\n",
    "    # recommended_symbols = []\n",
    "    recommended_symbols = [data[0] for data in recommendations]\n",
    "    cf_recos = get_cf_recos(recommended_symbols)\n",
    "    cf_recommendations = [(symbol, stock_meta_data.get(symbol)) for symbol in cf_recos]\n",
    "\n",
    "\n",
    "    reco_symbols = []\n",
    "    reco_insights = []\n",
    "    reco_plots = []\n",
    "\n",
    "    for data in cf_recommendations:\n",
    "        print(data[0], data[1])\n",
    "        # recommended_symbols.append(data[0])\n",
    "        symbol_df = price_data[price_data.SECURITYCODE == data[0]].sort_values(by = 'UNIX_TS').reset_index(drop = True)\n",
    "        \n",
    "        reco_symbol = '{} : {}'.format(data[0], data[1])\n",
    "        reco_acc = gr.Accordion(reco_symbol)\n",
    "        reco_symbols.append(reco_acc)\n",
    "\n",
    "        reco_insight = get_insights_str(data[0])\n",
    "        reco_insights = reco_insights + reco_insight\n",
    "\n",
    "        reco_plot = plot_ohlc_v1(symbol_df)\n",
    "        reco_grplot = gr.Plot(reco_plot, scale = 1, min_width= 1000)\n",
    "        reco_plots.append(reco_grplot)\n",
    "\n",
    "    return reco_symbols + reco_plots + reco_insights\n",
    "\n",
    "def get_recommendations_gradio_gr_v3(domains, reco_type, top_k = 10):\n",
    "    query = quey_generator(domains)\n",
    "    relevant_stocks = new_db.similarity_search_with_relevance_scores(query= query, k = top_k)\n",
    "    recommendations = [(relevant_stocks[idx][0].metadata.get('symbol'), relevant_stocks[idx][0].metadata.get('name'), relevant_stocks[idx][1]) for idx in range(len(relevant_stocks))]\n",
    "\n",
    "    cb_recos = [(data[0], data[1]) for data in recommendations]\n",
    "    recommended_symbols = [data[0] for data in recommendations]\n",
    "    cf_recos = get_cf_recos(recommended_symbols)\n",
    "    cf_recommendations = [(symbol, stock_meta_data.get(symbol)) for symbol in cf_recos]\n",
    "\n",
    "\n",
    "    reco_symbols = []\n",
    "    reco_insights = []\n",
    "    reco_plots = []\n",
    "\n",
    "    print('reco_type : \\n', reco_type)\n",
    "    print('domains : \\n', domains)\n",
    "    # print(len(cb_recos))\n",
    "    if reco_type == 'Content Base':\n",
    "        for data in cb_recos:\n",
    "            print(data[0], data[1])\n",
    "            symbol_df = price_data[price_data.SECURITYCODE == data[0]].sort_values(by = 'UNIX_TS').reset_index(drop = True)\n",
    "            \n",
    "            reco_symbol = '{} : {}'.format(data[0], data[1])\n",
    "            reco_acc = gr.Accordion(reco_symbol)\n",
    "            reco_symbols.append(reco_acc)\n",
    "\n",
    "            reco_insight = get_insights_str(data[0])\n",
    "            reco_insights = reco_insights + reco_insight\n",
    "\n",
    "            reco_plot = plot_ohlc_v1(symbol_df)\n",
    "            reco_grplot = gr.Plot(reco_plot, scale = 1, min_width= 1000)\n",
    "            reco_plots.append(reco_grplot)\n",
    "        print(len(reco_symbols + reco_plots + reco_insights))\n",
    "        return reco_symbols + reco_plots + reco_insights\n",
    "    elif reco_type == 'Collaborative Filtering':\n",
    "        for data in cf_recommendations:\n",
    "            print(data[0], data[1])\n",
    "            symbol_df = price_data[price_data.SECURITYCODE == data[0]].sort_values(by = 'UNIX_TS').reset_index(drop = True)\n",
    "            \n",
    "            reco_symbol = '{} : {}'.format(data[0], data[1])\n",
    "            reco_acc = gr.Accordion(reco_symbol)\n",
    "            reco_symbols.append(reco_acc)\n",
    "\n",
    "            reco_insight = get_insights_str(data[0])\n",
    "            reco_insights = reco_insights + reco_insight\n",
    "\n",
    "            reco_plot = plot_ohlc_v1(symbol_df)\n",
    "            reco_grplot = gr.Plot(reco_plot, scale = 1, min_width= 1000)\n",
    "            reco_plots.append(reco_grplot)\n",
    "        return reco_symbols + reco_plots + reco_insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio ui - me no like :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reco_type : \n",
      " Content Base\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "NTB NATIONS TRUST BANK PLC\n",
      "LOFC LOLC FINANCE PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "JKH JOHN KEELLS HOLDINGS PLC\n",
      "HNB HATTON NATIONAL BANK PLC\n",
      "LPL LAUGFS POWER PLC\n",
      "LCBF LANKA CREDIT AND BUSINESS FINANCE PLC\n",
      "TAJ TAL LANKA HOTELS PLC\n",
      "NDB NATIONAL DEVELOPMENT BANK PLC\n",
      "FCT First Capital Treasuries PLC\n",
      "170\n",
      "reco_type : \n",
      " Collaborative Filtering\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "LOFC LOLC FINANCE PLC\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "SAMP SAMPATH BANK PLC\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "HAYL HAYLEYS PLC\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "ACL ACL CABLES PLC\n",
      "DIAL DIALOG AXIATA PLC\n",
      "VONE VALLIBEL ONE PLC\n",
      "reco_type : \n",
      " Content Base\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "NTB NATIONS TRUST BANK PLC\n",
      "LOFC LOLC FINANCE PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "JKH JOHN KEELLS HOLDINGS PLC\n",
      "HNB HATTON NATIONAL BANK PLC\n",
      "LPL LAUGFS POWER PLC\n",
      "LCBF LANKA CREDIT AND BUSINESS FINANCE PLC\n",
      "TAJ TAL LANKA HOTELS PLC\n",
      "NDB NATIONAL DEVELOPMENT BANK PLC\n",
      "FCT First Capital Treasuries PLC\n",
      "170\n",
      "reco_type : \n",
      " Collaborative Filtering\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "LOFC LOLC FINANCE PLC\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "SAMP SAMPATH BANK PLC\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "HAYL HAYLEYS PLC\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "ACL ACL CABLES PLC\n",
      "DIAL DIALOG AXIATA PLC\n",
      "VONE VALLIBEL ONE PLC\n",
      "reco_type : \n",
      " Content Base\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "NTB NATIONS TRUST BANK PLC\n",
      "LOFC LOLC FINANCE PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "JKH JOHN KEELLS HOLDINGS PLC\n",
      "HNB HATTON NATIONAL BANK PLC\n",
      "LPL LAUGFS POWER PLC\n",
      "LCBF LANKA CREDIT AND BUSINESS FINANCE PLC\n",
      "TAJ TAL LANKA HOTELS PLC\n",
      "NDB NATIONAL DEVELOPMENT BANK PLC\n",
      "FCT First Capital Treasuries PLC\n",
      "170\n",
      "reco_type : \n",
      " Collaborative Filtering\n",
      "domains : \n",
      " ['finance', 'technology']\n",
      "LOFC LOLC FINANCE PLC\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "SAMP SAMPATH BANK PLC\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "HAYL HAYLEYS PLC\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "ACL ACL CABLES PLC\n",
      "DIAL DIALOG AXIATA PLC\n",
      "VONE VALLIBEL ONE PLC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\langchain_core\\vectorstores.py:311: UserWarning:\n",
      "\n",
      "Relevance scores must be between 0 and 1, got [(Document(page_content='DISTILLERIES COMPANY OF SRI LANKA PLC distillation, manufacture and distribution of liquor products.', metadata={'symbol': 'DIST', 'name': 'DISTILLERIES COMPANY OF SRI LANKA PLC'}), -0.030631132271688344), (Document(page_content='EXPOLANKA HOLDINGS PLC diversified conglomerate company. It is specialized in logistics, leisure, and investments. It manages a portfolio of holdings, which consists of a range of diverse business operations and provides various function-based services to its companies. The logistics sector consists mainly of its freight forwarding business, represented by the EFL brand. It is\\xa0engaged in providing air freight, ocean freight and other contract logistics services, such as warehousing and transport services. The sector also includes a GSA operation representing key strategic airlines. The leisure sector consists mainly of the corporate travel business, which provides airline ticketing, hotel reservations, leisure services, inbound operations, and event management services. The Investment sector includes the export of commodities (desiccated coconut, a selection of fruits and vegetables), value-added processing operations and information technology (IT) services.', metadata={'symbol': 'EXPO', 'name': 'EXPOLANKA HOLDINGS PLC'}), -0.06968499215776203), (Document(page_content='TAL LANKA HOTELS PLC hospitality trade.', metadata={'symbol': 'TAJ', 'name': 'TAL LANKA HOTELS PLC'}), -0.0790930116823636), (Document(page_content='HEMAS HOLDINGS PLC Conglomerate with focused interest in Consumer and Healthcare.', metadata={'symbol': 'HHL', 'name': 'HEMAS HOLDINGS PLC'}), -0.09469973680485677), (Document(page_content='JOHN KEELLS HOLDINGS PLC Travel & tourism, stock broking, banking, insurance, property development, real estate management, soft drinks, ice creams, processed meats, supermarketing, bunkering services & operation of a container terminal at the port of Colombo, freight forwarding, software and office automation solutions, BPO, tea & rubber broking', metadata={'symbol': 'JKH', 'name': 'JOHN KEELLS HOLDINGS PLC'}), -0.09575357660502304), (Document(page_content='JOHN KEELLS PLC provision of tea and rubber broking services. The Company operates through three segments: Produce Broking, Warehousing and Stock Broking.', metadata={'symbol': 'JKL', 'name': 'JOHN KEELLS PLC'}), -0.10592866877252316), (Document(page_content='DANKOTUWA PORCELAIN PLC manufacturing and marketing of porcelain tableware, targeted to export and domestic markets.', metadata={'symbol': 'DPL', 'name': 'DANKOTUWA PORCELAIN PLC'}), -0.1350080554900086), (Document(page_content='JETWING SYMPHONY PLC hoteliering.', metadata={'symbol': 'JETS', 'name': 'JETWING SYMPHONY PLC'}), -0.14706441438764073), (Document(page_content='LAUGFS POWER PLC power and energy, consumer retail, industrial, services, leisure and logistics', metadata={'symbol': 'LPL', 'name': 'LAUGFS POWER PLC'}), -0.16163095528888483), (Document(page_content='C I C HOLDINGS PLC merchandising and manufacturing. The Companys segments include Crop Solutions, Agri-Produce, Livestock Solutions, Industrial Solutions and Health & Personal care.', metadata={'symbol': 'CIC', 'name': 'C I C HOLDINGS PLC'}), -0.1816872075023701)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reco_type : \n",
      " Collaborative Filtering\n",
      "domains : \n",
      " ['Beverages', 'food']\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "LIOC LANKA IOC PLC\n",
      "ACL ACL CABLES PLC\n",
      "LOFC LOLC FINANCE PLC\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "HAYL HAYLEYS PLC\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "SAMP SAMPATH BANK PLC\n",
      "CIC C I C HOLDINGS PLC\n",
      "VONE VALLIBEL ONE PLC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\langchain_core\\vectorstores.py:311: UserWarning:\n",
      "\n",
      "Relevance scores must be between 0 and 1, got [(Document(page_content='DISTILLERIES COMPANY OF SRI LANKA PLC distillation, manufacture and distribution of liquor products.', metadata={'symbol': 'DIST', 'name': 'DISTILLERIES COMPANY OF SRI LANKA PLC'}), -0.030631132271688344), (Document(page_content='EXPOLANKA HOLDINGS PLC diversified conglomerate company. It is specialized in logistics, leisure, and investments. It manages a portfolio of holdings, which consists of a range of diverse business operations and provides various function-based services to its companies. The logistics sector consists mainly of its freight forwarding business, represented by the EFL brand. It is\\xa0engaged in providing air freight, ocean freight and other contract logistics services, such as warehousing and transport services. The sector also includes a GSA operation representing key strategic airlines. The leisure sector consists mainly of the corporate travel business, which provides airline ticketing, hotel reservations, leisure services, inbound operations, and event management services. The Investment sector includes the export of commodities (desiccated coconut, a selection of fruits and vegetables), value-added processing operations and information technology (IT) services.', metadata={'symbol': 'EXPO', 'name': 'EXPOLANKA HOLDINGS PLC'}), -0.06968499215776203), (Document(page_content='TAL LANKA HOTELS PLC hospitality trade.', metadata={'symbol': 'TAJ', 'name': 'TAL LANKA HOTELS PLC'}), -0.0790930116823636), (Document(page_content='HEMAS HOLDINGS PLC Conglomerate with focused interest in Consumer and Healthcare.', metadata={'symbol': 'HHL', 'name': 'HEMAS HOLDINGS PLC'}), -0.09469973680485677), (Document(page_content='JOHN KEELLS HOLDINGS PLC Travel & tourism, stock broking, banking, insurance, property development, real estate management, soft drinks, ice creams, processed meats, supermarketing, bunkering services & operation of a container terminal at the port of Colombo, freight forwarding, software and office automation solutions, BPO, tea & rubber broking', metadata={'symbol': 'JKH', 'name': 'JOHN KEELLS HOLDINGS PLC'}), -0.09575357660502304), (Document(page_content='JOHN KEELLS PLC provision of tea and rubber broking services. The Company operates through three segments: Produce Broking, Warehousing and Stock Broking.', metadata={'symbol': 'JKL', 'name': 'JOHN KEELLS PLC'}), -0.10592866877252316), (Document(page_content='DANKOTUWA PORCELAIN PLC manufacturing and marketing of porcelain tableware, targeted to export and domestic markets.', metadata={'symbol': 'DPL', 'name': 'DANKOTUWA PORCELAIN PLC'}), -0.1350080554900086), (Document(page_content='JETWING SYMPHONY PLC hoteliering.', metadata={'symbol': 'JETS', 'name': 'JETWING SYMPHONY PLC'}), -0.14706441438764073), (Document(page_content='LAUGFS POWER PLC power and energy, consumer retail, industrial, services, leisure and logistics', metadata={'symbol': 'LPL', 'name': 'LAUGFS POWER PLC'}), -0.16163095528888483), (Document(page_content='C I C HOLDINGS PLC merchandising and manufacturing. The Companys segments include Crop Solutions, Agri-Produce, Livestock Solutions, Industrial Solutions and Health & Personal care.', metadata={'symbol': 'CIC', 'name': 'C I C HOLDINGS PLC'}), -0.1816872075023701)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reco_type : \n",
      " Content Base\n",
      "domains : \n",
      " ['Beverages', 'food']\n",
      "DIST DISTILLERIES COMPANY OF SRI LANKA PLC\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "TAJ TAL LANKA HOTELS PLC\n",
      "HHL HEMAS HOLDINGS PLC\n",
      "JKH JOHN KEELLS HOLDINGS PLC\n",
      "JKL JOHN KEELLS PLC\n",
      "DPL DANKOTUWA PORCELAIN PLC\n",
      "JETS JETWING SYMPHONY PLC\n",
      "LPL LAUGFS POWER PLC\n",
      "CIC C I C HOLDINGS PLC\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "%%blocks\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    dd_input = gr.Dropdown(\n",
    "        [\"finance\", \"transport\", \"technology\", \"agriculture\"],\n",
    "        multiselect=True,\n",
    "        label=\"Domains\",\n",
    "        allow_custom_value=True,\n",
    "        scale=5\n",
    "    )\n",
    "    # ttxt_input = gr.Textbox(\n",
    "    #     placeholder = 'What kind of business do you prefer?'\n",
    "    # )\n",
    "\n",
    "    rad_btn = gr.Radio(\n",
    "        choices = ['Content Base','Collaborative Filtering'],\n",
    "        label = 'recommender type',\n",
    "        value = 'Content Base'\n",
    "    )\n",
    "    button = gr.Button(\"Generate Recommendations\")\n",
    "\n",
    "    # with gr.Tab(label = 'Collaborative Filtering'):\n",
    "    with gr.Column() as output_col:\n",
    "        # 1\n",
    "        with gr.Accordion(open=False) as acc1:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in1_1 = gr.Textbox(label='Return')\n",
    "                        in1_2 = gr.Textbox(label='max drow down')\n",
    "                        in1_3 = gr.Textbox(label='gkhv')\n",
    "                        in1_4 = gr.Textbox(label='rs')\n",
    "                        in1_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in1_6 = gr.Textbox(label='Return')\n",
    "                        in1_7 = gr.Textbox(label='max drow down')\n",
    "                        in1_8 = gr.Textbox(label='gkhv')\n",
    "                        in1_9 = gr.Textbox(label='rs')\n",
    "                        in1_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in1_11 = gr.Textbox(label='Return')\n",
    "                        in1_12 = gr.Textbox(label='max drow down')\n",
    "                        in1_13 = gr.Textbox(label='gkhv')\n",
    "                        in1_14 = gr.Textbox(label='rs')\n",
    "                        in1_15 = gr.Textbox(label='yangzhang')\n",
    "                plt1 = gr.Plot()\n",
    "        # 2\n",
    "        with gr.Accordion(open=False) as acc2:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in2_1 = gr.Textbox(label='Return')\n",
    "                        in2_2 = gr.Textbox(label='max drow down')\n",
    "                        in2_3 = gr.Textbox(label='gkhv')\n",
    "                        in2_4 = gr.Textbox(label='rs')\n",
    "                        in2_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in2_6 = gr.Textbox(label='Return')\n",
    "                        in2_7 = gr.Textbox(label='max drow down')\n",
    "                        in2_8 = gr.Textbox(label='gkhv')\n",
    "                        in2_9 = gr.Textbox(label='rs')\n",
    "                        in2_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in2_11 = gr.Textbox(label='Return')\n",
    "                        in2_12 = gr.Textbox(label='max drow down')\n",
    "                        in2_13 = gr.Textbox(label='gkhv')\n",
    "                        in2_14 = gr.Textbox(label='rs')\n",
    "                        in2_15 = gr.Textbox(label='yangzhang')\n",
    "                plt2 = gr.Plot()\n",
    "        # 3\n",
    "        with gr.Accordion(open=False) as acc3:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in3_1 = gr.Textbox(label='Return')\n",
    "                        in3_2 = gr.Textbox(label='max drow down')\n",
    "                        in3_3 = gr.Textbox(label='gkhv')\n",
    "                        in3_4 = gr.Textbox(label='rs')\n",
    "                        in3_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in3_6 = gr.Textbox(label='Return')\n",
    "                        in3_7 = gr.Textbox(label='max drow down')\n",
    "                        in3_8 = gr.Textbox(label='gkhv')\n",
    "                        in3_9 = gr.Textbox(label='rs')\n",
    "                        in3_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in3_11 = gr.Textbox(label='Return')\n",
    "                        in3_12 = gr.Textbox(label='max drow down')\n",
    "                        in3_13 = gr.Textbox(label='gkhv')\n",
    "                        in3_14 = gr.Textbox(label='rs')\n",
    "                        in3_15 = gr.Textbox(label='yangzhang')\n",
    "                plt3 = gr.Plot()\n",
    "        #4\n",
    "        with gr.Accordion(open=False) as acc4:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in4_1 = gr.Textbox(label='Return')\n",
    "                        in4_2 = gr.Textbox(label='max drow down')\n",
    "                        in4_3 = gr.Textbox(label='gkhv')\n",
    "                        in4_4 = gr.Textbox(label='rs')\n",
    "                        in4_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in4_6 = gr.Textbox(label='Return')\n",
    "                        in4_7 = gr.Textbox(label='max drow down')\n",
    "                        in4_8 = gr.Textbox(label='gkhv')\n",
    "                        in4_9 = gr.Textbox(label='rs')\n",
    "                        in4_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in4_11 = gr.Textbox(label='Return')\n",
    "                        in4_12 = gr.Textbox(label='max drow down')\n",
    "                        in4_13 = gr.Textbox(label='gkhv')\n",
    "                        in4_14 = gr.Textbox(label='rs')\n",
    "                        in4_15 = gr.Textbox(label='yangzhang')\n",
    "                plt4 = gr.Plot()\n",
    "        \n",
    "        # 5\n",
    "        with gr.Accordion(open=False) as acc5:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in5_1 = gr.Textbox(label='Return')\n",
    "                        in5_2 = gr.Textbox(label='max drow down')\n",
    "                        in5_3 = gr.Textbox(label='gkhv')\n",
    "                        in5_4 = gr.Textbox(label='rs')\n",
    "                        in5_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in5_6 = gr.Textbox(label='Return')\n",
    "                        in5_7 = gr.Textbox(label='max drow down')\n",
    "                        in5_8 = gr.Textbox(label='gkhv')\n",
    "                        in5_9 = gr.Textbox(label='rs')\n",
    "                        in5_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in5_11 = gr.Textbox(label='Return')\n",
    "                        in5_12 = gr.Textbox(label='max drow down')\n",
    "                        in5_13 = gr.Textbox(label='gkhv')\n",
    "                        in5_14 = gr.Textbox(label='rs')\n",
    "                        in5_15 = gr.Textbox(label='yangzhang')\n",
    "                plt5 = gr.Plot()\n",
    "\n",
    "        # 6\n",
    "        with gr.Accordion(open=False) as acc6:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in6_1 = gr.Textbox(label='Return')\n",
    "                        in6_2 = gr.Textbox(label='max drow down')\n",
    "                        in6_3 = gr.Textbox(label='gkhv')\n",
    "                        in6_4 = gr.Textbox(label='rs')\n",
    "                        in6_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in6_6 = gr.Textbox(label='Return')\n",
    "                        in6_7 = gr.Textbox(label='max drow down')\n",
    "                        in6_8 = gr.Textbox(label='gkhv')\n",
    "                        in6_9 = gr.Textbox(label='rs')\n",
    "                        in6_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in6_11 = gr.Textbox(label='Return')\n",
    "                        in6_12 = gr.Textbox(label='max drow down')\n",
    "                        in6_13 = gr.Textbox(label='gkhv')\n",
    "                        in6_14 = gr.Textbox(label='rs')\n",
    "                        in6_15 = gr.Textbox(label='yangzhang')\n",
    "                plt6 = gr.Plot()\n",
    "            #7\n",
    "        with gr.Accordion(open=False) as acc7:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in7_1 = gr.Textbox(label='Return')\n",
    "                        in7_2 = gr.Textbox(label='max drow down')\n",
    "                        in7_3 = gr.Textbox(label='gkhv')\n",
    "                        in7_4 = gr.Textbox(label='rs')\n",
    "                        in7_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in7_6 = gr.Textbox(label='Return')\n",
    "                        in7_7 = gr.Textbox(label='max drow down')\n",
    "                        in7_8 = gr.Textbox(label='gkhv')\n",
    "                        in7_9 = gr.Textbox(label='rs')\n",
    "                        in7_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in7_11 = gr.Textbox(label='Return')\n",
    "                        in7_12 = gr.Textbox(label='max drow down')\n",
    "                        in7_13 = gr.Textbox(label='gkhv')\n",
    "                        in7_14 = gr.Textbox(label='rs')\n",
    "                        in7_15 = gr.Textbox(label='yangzhang')\n",
    "                plt7 = gr.Plot()\n",
    "        \n",
    "        # 8\n",
    "        with gr.Accordion(open=False) as acc8:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in8_1 = gr.Textbox(label='Return')\n",
    "                        in8_2 = gr.Textbox(label='max drow down')\n",
    "                        in8_3 = gr.Textbox(label='gkhv')\n",
    "                        in8_4 = gr.Textbox(label='rs')\n",
    "                        in8_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in8_6 = gr.Textbox(label='Return')\n",
    "                        in8_7 = gr.Textbox(label='max drow down')\n",
    "                        in8_8 = gr.Textbox(label='gkhv')\n",
    "                        in8_9 = gr.Textbox(label='rs')\n",
    "                        in8_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in8_11 = gr.Textbox(label='Return')\n",
    "                        in8_12 = gr.Textbox(label='max drow down')\n",
    "                        in8_13 = gr.Textbox(label='gkhv')\n",
    "                        in8_14 = gr.Textbox(label='rs')\n",
    "                        in8_15 = gr.Textbox(label='yangzhang')\n",
    "                plt8 = gr.Plot()\n",
    "\n",
    "        # 9\n",
    "        with gr.Accordion(open=False) as acc9:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in9_1 = gr.Textbox(label='Return')\n",
    "                        in9_2 = gr.Textbox(label='max drow down')\n",
    "                        in9_3 = gr.Textbox(label='gkhv')\n",
    "                        in9_4 = gr.Textbox(label='rs')\n",
    "                        in9_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in9_6 = gr.Textbox(label='Return')\n",
    "                        in9_7 = gr.Textbox(label='max drow down')\n",
    "                        in9_8 = gr.Textbox(label='gkhv')\n",
    "                        in9_9 = gr.Textbox(label='rs')\n",
    "                        in9_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in9_11 = gr.Textbox(label='Return')\n",
    "                        in9_12 = gr.Textbox(label='max drow down')\n",
    "                        in9_13 = gr.Textbox(label='gkhv')\n",
    "                        in9_14 = gr.Textbox(label='rs')\n",
    "                        in9_15 = gr.Textbox(label='yangzhang')\n",
    "                plt9 = gr.Plot()\n",
    "\n",
    "        with gr.Accordion(open=False) as acc10:\n",
    "            with gr.Row():\n",
    "                with gr.Tab(label='Year to Date'):\n",
    "                    with gr.Column():\n",
    "                        in10_1 = gr.Textbox(label='Return')\n",
    "                        in10_2 = gr.Textbox(label='max drow down')\n",
    "                        in10_3 = gr.Textbox(label='gkhv')\n",
    "                        in10_4 = gr.Textbox(label='rs')\n",
    "                        in10_5 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Year'):\n",
    "                    with gr.Column():\n",
    "                        in10_6 = gr.Textbox(label='Return')\n",
    "                        in10_7 = gr.Textbox(label='max drow down')\n",
    "                        in10_8 = gr.Textbox(label='gkhv')\n",
    "                        in10_9 = gr.Textbox(label='rs')\n",
    "                        in10_10 = gr.Textbox(label='yangzhang')\n",
    "                with gr.Tab(label='Last Month'):\n",
    "                    with gr.Column():\n",
    "                        in10_11 = gr.Textbox(label='Return')\n",
    "                        in10_12 = gr.Textbox(label='max drow down')\n",
    "                        in10_13 = gr.Textbox(label='gkhv')\n",
    "                        in10_14 = gr.Textbox(label='rs')\n",
    "                        in10_15 = gr.Textbox(label='yangzhang')\n",
    "                plt10 = gr.Plot()\n",
    "    outputs = [acc1,acc2,acc3,acc4,acc5,acc6,acc7,acc8,acc9,acc10,\n",
    "            plt1,plt2,plt3,plt4,plt5,plt6,plt7,plt8,plt9,plt10,\n",
    "            in1_1, in1_2, in1_3, in1_4, in1_5, \n",
    "            in1_6, in1_7, in1_8, in1_9, in1_10, \n",
    "            in1_11, in1_12, in1_13, in1_14, in1_15, \n",
    "            in2_1, in2_2, in2_3, in2_4, in2_5, \n",
    "            in2_6, in2_7, in2_8, in2_9, in2_10, \n",
    "            in2_11, in2_12, in2_13, in2_14, in2_15, \n",
    "            in3_1, in3_2, in3_3, in3_4, in3_5, \n",
    "            in3_6, in3_7, in3_8, in3_9, in3_10, \n",
    "            in3_11, in3_12, in3_13, in3_14, in3_15, \n",
    "            in4_1, in4_2, in4_3, in4_4, in4_5, \n",
    "            in4_6, in4_7, in4_8, in4_9, in4_10, \n",
    "            in4_11, in4_12, in4_13, in4_14, in4_15, \n",
    "            in5_1, in5_2, in5_3, in5_4, in5_5, \n",
    "            in5_6, in5_7, in5_8, in5_9, in5_10, \n",
    "            in5_11, in5_12, in5_13, in5_14, in5_15, \n",
    "            in6_1, in6_2, in6_3, in6_4, in6_5, \n",
    "            in6_6, in6_7, in6_8, in6_9, in6_10, \n",
    "            in6_11, in6_12, in6_13, in6_14, in6_15, \n",
    "            in7_1, in7_2, in7_3, in7_4, in7_5, \n",
    "            in7_6, in7_7, in7_8, in7_9, in7_10, \n",
    "            in7_11, in7_12, in7_13, in7_14, in7_15, \n",
    "            in8_1, in8_2, in8_3, in8_4, in8_5, \n",
    "            in8_6, in8_7, in8_8, in8_9, in8_10, \n",
    "            in8_11, in8_12, in8_13, in8_14, in8_15, \n",
    "            in9_1, in9_2, in9_3, in9_4, in9_5, \n",
    "            in9_6, in9_7, in9_8, in9_9, in9_10, \n",
    "            in9_11, in9_12, in9_13, in9_14, in9_15, \n",
    "            in10_1, in10_2, in10_3, in10_4, in10_5, \n",
    "            in10_6, in10_7, in10_8, in10_9, in10_10, \n",
    "            in10_11, in10_12, in10_13, in10_14, in10_15]\n",
    "    inputs = [dd_input, rad_btn]\n",
    "    \n",
    "    button.click(fn = get_recommendations_gradio_gr_v3, inputs = inputs, outputs = outputs)\n",
    "    rad_btn.change(fn = get_recommendations_gradio_gr_v3, inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo.launch(server_port = 7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOLLLLLLLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "returned :  15\n",
      "15\n",
      "LOFC LOLC FINANCE PLC\n",
      "returned :  15\n",
      "30\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "returned :  15\n",
      "45\n",
      "ACL ACL CABLES PLC\n",
      "returned :  15\n",
      "60\n",
      "LIOC LANKA IOC PLC\n",
      "returned :  15\n",
      "75\n",
      "HAYL HAYLEYS PLC\n",
      "returned :  15\n",
      "90\n",
      "SAMP SAMPATH BANK PLC\n",
      "returned :  15\n",
      "105\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "returned :  15\n",
      "120\n",
      "VONE VALLIBEL ONE PLC\n",
      "returned :  15\n",
      "135\n",
      "COMB COMMERCIAL BANK OF CEYLON PLC\n",
      "returned :  15\n",
      "150\n",
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\tf_tr_recommender\\lib\\site-packages\\langchain_core\\vectorstores.py:311: UserWarning:\n",
      "\n",
      "Relevance scores must be between 0 and 1, got [(Document(page_content='HAYLEYS FIBRE PLC manufacture and export of coir fibre products. The Company is a total solutions provider for a range of applications based on coconut fibre and coir fibre in Sri Lanka. Its coconut fibre-related products and services include Bio-Engineering, Horticulture & Bedding, Coir Twine & Yarn, Growing Media', metadata={'symbol': 'HEXP', 'name': 'HAYLEYS FIBRE PLC'}), -0.03889149311133844), (Document(page_content='MYLAND DEVELOPMENTS PLC Real Estate and Construction.', metadata={'symbol': 'MDL', 'name': 'MYLAND DEVELOPMENTS PLC'}), -0.06313638342353323), (Document(page_content='C I C HOLDINGS PLC merchandising and manufacturing. The Companys segments include Crop Solutions, Agri-Produce, Livestock Solutions, Industrial Solutions and Health & Personal care.', metadata={'symbol': 'CIC', 'name': 'C I C HOLDINGS PLC'}), -0.06426271580313836), (Document(page_content='EXTERMINATORS PLC an environmental enhancement technology company, engages in the provision of pest control services and related products', metadata={'symbol': 'EXT', 'name': 'EXTERMINATORS PLC'}), -0.06647314942014071), (Document(page_content='TAL LANKA HOTELS PLC hospitality trade.', metadata={'symbol': 'TAJ', 'name': 'TAL LANKA HOTELS PLC'}), -0.0790157986558917)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "EXPO EXPOLANKA HOLDINGS PLC\n",
      "returned :  15\n",
      "15\n",
      "LIOC LANKA IOC PLC\n",
      "returned :  15\n",
      "30\n",
      "ACL ACL CABLES PLC\n",
      "returned :  15\n",
      "45\n",
      "LOFC LOLC FINANCE PLC\n",
      "returned :  15\n",
      "60\n",
      "RCL ROYAL CERAMICS LANKA PLC\n",
      "returned :  15\n",
      "75\n",
      "LOLC L O L C HOLDINGS PLC\n",
      "returned :  15\n",
      "90\n",
      "HAYL HAYLEYS PLC\n",
      "returned :  15\n",
      "105\n",
      "CIC C I C HOLDINGS PLC\n",
      "returned :  15\n",
      "120\n",
      "VONE VALLIBEL ONE PLC\n",
      "returned :  15\n",
      "135\n",
      "SAMP SAMPATH BANK PLC\n",
      "returned :  15\n",
      "150\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    input = gr.Dropdown(\n",
    "        [\"finance\", \"transport\", \"technology\", \"agriculture\"],\n",
    "        multiselect=True,\n",
    "        label=\"Domains\",\n",
    "        allow_custom_value=True,\n",
    "        scale=5\n",
    "    )\n",
    "\n",
    "    button = gr.Button(\"Generate Recommendations\")\n",
    "\n",
    "    with gr.Column() as output_col:\n",
    "        with gr.Accordion(open = False) as acc1:\n",
    "            with gr.Row():\n",
    "                txt1 = gr.TextArea()\n",
    "                plt1 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc2:\n",
    "            with gr.Row():\n",
    "                txt2 = gr.TextArea()\n",
    "                plt2 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc3:\n",
    "            with gr.Row():\n",
    "                txt3 = gr.TextArea()\n",
    "                plt3 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc4:\n",
    "            with gr.Row():\n",
    "                txt4 = gr.TextArea()\n",
    "                plt4 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc5:\n",
    "            with gr.Row():\n",
    "                txt5 = gr.TextArea()\n",
    "                plt5 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc6:\n",
    "            with gr.Row():\n",
    "                txt6 = gr.TextArea()\n",
    "                plt6 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc7:\n",
    "            with gr.Row():\n",
    "                txt7 = gr.TextArea()\n",
    "                plt7 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc8:\n",
    "            with gr.Row():\n",
    "                txt8 = gr.TextArea()\n",
    "                plt8 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc9:\n",
    "            with gr.Row():\n",
    "                txt9 = gr.TextArea()\n",
    "                plt9 = gr.Plot()\n",
    "        with gr.Accordion(open = False) as acc10:\n",
    "            with gr.Row():\n",
    "                txt10 = gr.TextArea()\n",
    "                plt10 = gr.Plot()\n",
    "\n",
    "\n",
    "    outputs = [acc1,acc2,acc3,acc4,acc5,acc6,acc7,acc8,acc9,acc10,\n",
    "            txt1,txt2,txt3,txt4,txt5,txt6,txt7,txt8,txt9,txt10,\n",
    "            plt1,plt2,plt3,plt4,plt5,plt6,plt7,plt8,plt9,plt10]\n",
    "\n",
    "    button.click(fn = get_recommendations_gradio, inputs = input, outputs = outputs)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    inputs = gr.Dropdown(\n",
    "        [\"finance\", \"transport\", \"technology\", \"agriculture\"],\n",
    "        multiselect=True,\n",
    "        label=\"Domains\",\n",
    "        allow_custom_value=True,\n",
    "        scale=5\n",
    "    )\n",
    "    \n",
    "    button = gr.Button(\"Generate Recommendations\")\n",
    "\n",
    "    outputs = [gr.Plot(), gr.Plot(),gr.Plot(),\n",
    "               gr.Plot(),gr.Plot(),gr.Plot(),\n",
    "               gr.Plot(),gr.Plot(),gr.Plot(),gr.Plot()]\n",
    "\n",
    "    button.click(get_recommendations_gradio, inputs=inputs, outputs=outputs)\n",
    "    \n",
    "\n",
    "    demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tr_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
